<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>INF511: Modern Regression I - 4&nbsp; Ordinary Least Squares</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./hypothesis.html" rel="next">
<link href="./prob.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ordinary Least Squares</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">INF511: Modern Regression I</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/joseph-mihaljevic/inf511-book" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Software</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Rintro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability distributions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ols.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ordinary Least Squares</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hypothesis.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./max-lik.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">ANOVA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayesian.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Bayesian inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">Appendices</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./syllabus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Syllabus</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#lecture-material" id="toc-lecture-material" class="nav-link active" data-scroll-target="#lecture-material"><span class="toc-section-number">4.1</span>  Lecture material</a></li>
  <li><a href="#in-class-code" id="toc-in-class-code" class="nav-link" data-scroll-target="#in-class-code">In-class Code</a></li>
  <li><a href="#generate-the-data" id="toc-generate-the-data" class="nav-link" data-scroll-target="#generate-the-data"><span class="toc-section-number">4.2</span>  Generate the data</a></li>
  <li><a href="#plot-the-relationship" id="toc-plot-the-relationship" class="nav-link" data-scroll-target="#plot-the-relationship"><span class="toc-section-number">4.3</span>  Plot the relationship</a></li>
  <li><a href="#sec-lm-output" id="toc-sec-lm-output" class="nav-link" data-scroll-target="#sec-lm-output"><span class="toc-section-number">4.4</span>  Estimate the coefficients using R’s <code>lm()</code> function</a></li>
  <li><a href="#estimate-the-coefficients-manually" id="toc-estimate-the-coefficients-manually" class="nav-link" data-scroll-target="#estimate-the-coefficients-manually"><span class="toc-section-number">4.5</span>  Estimate the coefficients manually</a></li>
  <li><a href="#sec-est-plot" id="toc-sec-est-plot" class="nav-link" data-scroll-target="#sec-est-plot"><span class="toc-section-number">4.6</span>  Plot the <em>estimated</em> relationships</a></li>
  <li><a href="#why-are-the-hatb-different-from-true-b" id="toc-why-are-the-hatb-different-from-true-b" class="nav-link" data-scroll-target="#why-are-the-hatb-different-from-true-b"><span class="toc-section-number">4.7</span>  Why are the <span class="math inline">\(\hat{B}\)</span> different from true <span class="math inline">\(B\)</span>?</a></li>
  <li><a href="#understanding-uncertainty-in-hatb" id="toc-understanding-uncertainty-in-hatb" class="nav-link" data-scroll-target="#understanding-uncertainty-in-hatb"><span class="toc-section-number">4.8</span>  Understanding Uncertainty in <span class="math inline">\(\hat{B}\)</span></a></li>
  <li><a href="#sec-conf-beta" id="toc-sec-conf-beta" class="nav-link" data-scroll-target="#sec-conf-beta"><span class="toc-section-number">4.9</span>  Confidence Intervals for <span class="math inline">\(\hat{B}\)</span></a></li>
  <li>
<a href="#propagate-uncertainty-in-hatb-for-predictions-of-y" id="toc-propagate-uncertainty-in-hatb-for-predictions-of-y" class="nav-link" data-scroll-target="#propagate-uncertainty-in-hatb-for-predictions-of-y"><span class="toc-section-number">4.10</span>  Propagate uncertainty in <span class="math inline">\(\hat{B}\)</span> for predictions of <span class="math inline">\(Y\)</span></a>
  <ul class="collapse">
<li><a href="#multivariate-t-distribution-method" id="toc-multivariate-t-distribution-method" class="nav-link" data-scroll-target="#multivariate-t-distribution-method"><span class="toc-section-number">4.10.1</span>  Multivariate <span class="math inline">\(t\)</span>-distribution method</a></li>
  <li><a href="#predict-function-method" id="toc-predict-function-method" class="nav-link" data-scroll-target="#predict-function-method"><span class="toc-section-number">4.10.2</span>  <code>predict()</code> function method</a></li>
  <li><a href="#compare-the-two-methods" id="toc-compare-the-two-methods" class="nav-link" data-scroll-target="#compare-the-two-methods"><span class="toc-section-number">4.10.3</span>  Compare the two methods</a></li>
  </ul>
</li>
  <li><a href="#multiple-linear-regression" id="toc-multiple-linear-regression" class="nav-link" data-scroll-target="#multiple-linear-regression"><span class="toc-section-number">4.11</span>  Multiple Linear Regression</a></li>
  <li>
<a href="#footnotes" id="toc-footnotes" class="nav-link" data-scroll-target="#footnotes"><span class="toc-section-number">4.12</span>  Footnotes</a>
  <ul class="collapse">
<li><a href="#sec-crossprod" id="toc-sec-crossprod" class="nav-link" data-scroll-target="#sec-crossprod"><span class="toc-section-number">4.12.1</span>  Euclidean norm &amp; cross product</a></li>
  <li><a href="#sec-solve" id="toc-sec-solve" class="nav-link" data-scroll-target="#sec-solve"><span class="toc-section-number">4.12.2</span>  <code>solve()</code> and Inverse of matrix</a></li>
  <li><a href="#sec-mlr" id="toc-sec-mlr" class="nav-link" data-scroll-target="#sec-mlr"><span class="toc-section-number">4.12.3</span>  Multiple linear regression with a categorical input</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/joseph-mihaljevic/inf511-book/blob/main/ols.qmd" class="toc-action">View source</a></p><p><a href="https://github.com/joseph-mihaljevic/inf511-book/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-ols" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ordinary Least Squares</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><section id="lecture-material" class="level2" data-number="4.1"><h2 data-number="4.1" class="anchored" data-anchor-id="lecture-material">
<span class="header-section-number">4.1</span> Lecture material</h2>
<p>Please download and print the lecture materials from <a href="https://bblearn.nau.edu/" target="_blank">Bblearn</a>. After lectures, the recordings will appear in the Bblearn Collaborate Ultra section.</p>
</section><section id="in-class-code" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="in-class-code">In-class Code</h2>
<p>Remember that our goal is to estimate the linear relationship between data observations of response variable, <span class="math inline">\(y\)</span>, and its measured covariate, <span class="math inline">\(x\)</span>, following: <span class="math inline">\(Y = XB + \epsilon\)</span>, where <span class="math inline">\(\epsilon \sim N(0, \sigma^2 I).\)</span> Our coefficients to estimate are therefore <span class="math inline">\(\hat{B}\)</span>, which is a column vector of the intercept and slope. We also estimate the standard deviation of the residuals (i.e., residual error), <span class="math inline">\(\hat{\sigma}\)</span>. To estimate the coefficients, we are attempting to minimize the residual sum of squares, <span class="math inline">\(|| \epsilon || ^ 2\)</span>. See <a href="#sec-crossprod">Footnotes&nbsp;<span>4.12.1</span></a> for more information regarding this notation.</p>
</section><section id="generate-the-data" class="level2" data-number="4.2"><h2 data-number="4.2" class="anchored" data-anchor-id="generate-the-data">
<span class="header-section-number">4.2</span> Generate the data</h2>
<p>We’ll start with a very small data set to emphasize the basics, and then the in-class activity will go into more depth. Here, we’ll implement the OLS estimation with a single covariate that we demonstrated in lecture.</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">n</span> <span class="op">=</span> <span class="fl">4</span> <span class="co"># number observations</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">2</span> <span class="co"># number of parameters</span></span>
<span></span>
<span><span class="co"># Covariate:</span></span>
<span><span class="va">x0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span> <span class="co"># placeholder for intercept</span></span>
<span><span class="va">x1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span>,<span class="fl">5</span>,<span class="fl">1</span><span class="op">)</span> <span class="co"># value of x</span></span>
<span><span class="va">xmat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x0</span>,<span class="va">x1</span><span class="op">)</span>, </span>
<span>               nrow <span class="op">=</span> <span class="va">n</span>, </span>
<span>               ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">xmat</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    1    2
[2,]    1    3
[3,]    1    5
[4,]    1    1</code></pre>
</div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Coefficients:</span></span>
<span><span class="co">## betas[1]: intercept</span></span>
<span><span class="co">## betas[2]: slope</span></span>
<span><span class="va">betas</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="va">xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]    8
[2,]   10
[3,]   14
[4,]    6</code></pre>
</div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># residuals</span></span>
<span><span class="va">epsilon</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Data observations:</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span> <span class="op">+</span> <span class="va">epsilon</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="plot-the-relationship" class="level2" data-number="4.3"><h2 data-number="4.3" class="anchored" data-anchor-id="plot-the-relationship">
<span class="header-section-number">4.3</span> Plot the relationship</h2>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot in layers</span></span>
<span><span class="co">## Create a blank plotting canvas, specifying axis limits</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x<span class="op">=</span><span class="cn">NA</span>,y<span class="op">=</span><span class="cn">NA</span>, xlab <span class="op">=</span> <span class="st">"x"</span>, ylab <span class="op">=</span> <span class="st">"y"</span>,</span>
<span>     ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span>, xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## Add data points</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">## Add known linear relationship</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>coef <span class="op">=</span> <span class="va">betas</span>, col <span class="op">=</span> <span class="st">"black"</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Show the residuals:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span>x0 <span class="op">=</span> <span class="va">x1</span>, x1 <span class="op">=</span> <span class="va">x1</span>,</span>
<span>         y0 <span class="op">=</span> <span class="va">y</span>, y1 <span class="op">=</span> <span class="va">y</span> <span class="op">-</span> <span class="va">epsilon</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Show the model predictions, \hat{y}:</span></span>
<span><span class="va">y_hat</span> <span class="op">=</span> <span class="va">xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">y_hat</span> <span class="op">~</span> <span class="va">x1</span>, cex <span class="op">=</span> <span class="fl">1.25</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section><section id="sec-lm-output" class="level2" data-number="4.4"><h2 data-number="4.4" class="anchored" data-anchor-id="sec-lm-output">
<span class="header-section-number">4.4</span> Estimate the coefficients using R’s <code>lm()</code> function</h2>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Run the model:</span></span>
<span><span class="va">lm_out</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">x1</span><span class="op">)</span></span>
<span><span class="co"># Show the summary output</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm_out</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ 1 + x1)

Residuals:
     1      2      3      4 
-1.029 -1.657  1.086  1.600 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)   5.7714     2.0500   2.815    0.106
x1            1.6286     0.6565   2.481    0.131

Residual standard error: 1.942 on 2 degrees of freedom
Multiple R-squared:  0.7547,    Adjusted R-squared:  0.6321 
F-statistic: 6.153 on 1 and 2 DF,  p-value: 0.1313</code></pre>
</div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract the estimated coefficients</span></span>
<span><span class="va">lm_coef</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">lm_out</span><span class="op">)</span></span>
<span><span class="va">lm_coef</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)          x1 
   5.771429    1.628571 </code></pre>
</div>
</div>
</section><section id="estimate-the-coefficients-manually" class="level2" data-number="4.5"><h2 data-number="4.5" class="anchored" data-anchor-id="estimate-the-coefficients-manually">
<span class="header-section-number">4.5</span> Estimate the coefficients manually</h2>
<p>Now we will use the matrix algebra and derivation of normal equations to estimate the intercept and slope from the observations, <span class="math inline">\(Y\)</span>. Remember that we estimate the coefficient vector, <span class="math inline">\(\hat{B}\)</span> from: <span class="math display">\[X^TX \hat{B} = X^T Y\]</span> <span class="math display">\[\hat{B} = (X^TX)^{-1} X^T Y\]</span> These equations include the multiplicative inverse matrix, <span class="math inline">\((X^TX)^{-1}\)</span>. See the <a href="#sec-solve">Footnotes&nbsp;<span>4.12.2</span></a> for more information about inverse matrices and the <code><a href="https://rdrr.io/r/base/solve.html">solve()</a></code> function.</p>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Let's break up the normal equations into intermediates:</span></span>
<span><span class="va">xtx</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">xmat</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">xmat</span></span>
<span></span>
<span><span class="co">## Use solve() to find inverse of xtx</span></span>
<span><span class="co">## why solve()? See Appendix, linked above.</span></span>
<span><span class="va">inv_xtx</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="va">xtx</span><span class="op">)</span></span>
<span><span class="va">xty</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">xmat</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">y</span></span>
<span></span>
<span><span class="va">bhat</span> <span class="op">=</span> <span class="va">inv_xtx</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">xty</span></span>
<span></span>
<span><span class="co"># More efficient:</span></span>
<span><span class="co"># Remember, xtx * bhat = xty</span></span>
<span><span class="co"># So we can use solve() again</span></span>
<span><span class="va">bhat_solve</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="va">xtx</span>, <span class="va">xty</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Are they the same?</span></span>
<span></span>
<span><span class="co"># How does this manual solution compare to lm()'s solution?</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="sec-est-plot" class="level2" data-number="4.6"><h2 data-number="4.6" class="anchored" data-anchor-id="sec-est-plot">
<span class="header-section-number">4.6</span> Plot the <em>estimated</em> relationships</h2>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot in layers</span></span>
<span><span class="co">## Create a blank plotting canvas, specifying axis limits</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="cn">NA</span>,<span class="cn">NA</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"x"</span>, ylab <span class="op">=</span> <span class="st">"y"</span>,</span>
<span>     ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span>,</span>
<span>     xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## Add data points</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">## Add known linear relationship</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>coef <span class="op">=</span> <span class="va">betas</span>,</span>
<span>       col <span class="op">=</span> <span class="st">"black"</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Show the residuals:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span></span>
<span>  x0 <span class="op">=</span> <span class="va">x1</span>,</span>
<span>  x1 <span class="op">=</span> <span class="va">x1</span>,</span>
<span>  y0 <span class="op">=</span> <span class="va">y</span>,</span>
<span>  y1 <span class="op">=</span> <span class="va">y</span> <span class="op">-</span> <span class="va">epsilon</span>,</span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Show the model predictions, \hat{y}:</span></span>
<span><span class="va">y_hat</span> <span class="op">=</span> <span class="va">xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">y_hat</span> <span class="op">~</span> <span class="va">x1</span>,</span>
<span>       cex <span class="op">=</span> <span class="fl">1.25</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add the lm() estimate:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>coef <span class="op">=</span> <span class="va">lm_coef</span>,</span>
<span>       col <span class="op">=</span> <span class="st">"orange"</span>, lty <span class="op">=</span> <span class="fl">2</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add the manual OLS estimate:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>coef <span class="op">=</span> <span class="va">bhat_solve</span>,</span>
<span>       col <span class="op">=</span> <span class="st">"purple"</span>, lty <span class="op">=</span> <span class="fl">3</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section><section id="why-are-the-hatb-different-from-true-b" class="level2" data-number="4.7"><h2 data-number="4.7" class="anchored" data-anchor-id="why-are-the-hatb-different-from-true-b">
<span class="header-section-number">4.7</span> Why are the <span class="math inline">\(\hat{B}\)</span> different from true <span class="math inline">\(B\)</span>?</h2>
<p>Remember, we are estimating the coefficients by minimizing the sum of squared errors (SSE), <span class="math inline">\(|| \epsilon ||^2\)</span>.</p>
<div class="cell">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># True sum of squares:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9</code></pre>
</div>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Estimated (i.e., minimized sum of squares):</span></span>
<span><span class="co">## From lm()</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">lm_out</span><span class="op">$</span><span class="va">residuals</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## From manual OLS</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">bhat_solve</span><span class="op">)</span> <span class="op">)</span><span class="op">^</span><span class="fl">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7.099748e-30</code></pre>
</div>
</div>
<p>You can see that the OLS strategy effectively minimized the SSE to zero.</p>
</section><section id="understanding-uncertainty-in-hatb" class="level2" data-number="4.8"><h2 data-number="4.8" class="anchored" data-anchor-id="understanding-uncertainty-in-hatb">
<span class="header-section-number">4.8</span> Understanding Uncertainty in <span class="math inline">\(\hat{B}\)</span>
</h2>
<p>While the OLS analysis estimates the regression coefficients, <span class="math inline">\(\hat{B}\)</span>, from the observed data <span class="math inline">\(Y\)</span>, our estimates of these coefficients have error (i.e., uncertainty), such that the estimates are only as good as the data. Specifically, if we have fewer data points (i.e., <span class="math inline">\(n\)</span> is low), we have less certainty in <span class="math inline">\(\hat{B}\)</span>. In lecture, we showed, that: <span class="math display">\[\hat{B} \sim N \left( B, (X^TX)^{-1} \hat{\sigma}^2 \right), \]</span> and we know that <span class="math inline">\(\hat{\sigma}^2\)</span> depends on sample size <span class="math inline">\(n\)</span>, following: <span class="math display">\[\hat{\sigma}^2 \quad = \quad \frac{1}{n-p} (Y_{obs} - Y_{pred})^T (Y_{obs} - Y_{pred}) \quad = \quad \frac{1}{n-p} \hat{\epsilon}^T \hat{\epsilon}\]</span></p>
<p>Using these equations, we showed then that <span class="math inline">\(SE(\beta_i) = \sqrt{diag\left( (X^TX)^{-1} \right)_i \hat{\sigma}^2}\)</span>. Let’s calculate this manually and compare to the output of the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function.</p>
<div class="cell">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract the model summary, which has useful components</span></span>
<span><span class="va">lm_out_summary</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm_out</span><span class="op">)</span></span>
<span><span class="co"># Extract the estimated residual standard deviation, sigma</span></span>
<span><span class="va">est_sigma</span> <span class="op">=</span> <span class="va">lm_out_summary</span><span class="op">$</span><span class="va">sigma</span></span>
<span><span class="va">est_sigma</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.942017</code></pre>
</div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># We already calculated (X^T X)^{-1} as inv_xtx</span></span>
<span><span class="va">beta_cov_mat</span> <span class="op">=</span> <span class="va">inv_xtx</span> <span class="op">*</span> <span class="va">est_sigma</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">beta_cov_mat</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]       [,2]
[1,]  4.202449 -1.1853061
[2,] -1.185306  0.4310204</code></pre>
</div>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">se_beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">beta_cov_mat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">se_beta</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.0499876 0.6565214</code></pre>
</div>
</div>
<p>Compare these values to the output of the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> of <a href="#sec-lm-output"><span>Section&nbsp;4.4</span></a> in the column labelled <code>Std. Error</code>.</p>
</section><section id="sec-conf-beta" class="level2" data-number="4.9"><h2 data-number="4.9" class="anchored" data-anchor-id="sec-conf-beta">
<span class="header-section-number">4.9</span> Confidence Intervals for <span class="math inline">\(\hat{B}\)</span>
</h2>
<p>To calculate confidence intervals for <span class="math inline">\(\hat{B}\)</span>, we first must understand the <span class="math inline">\(t\)</span> (a.k.a. Student’s <span class="math inline">\(t\)</span>) probability distribution. This distribution represents the case when we are estimating the mean of a normally distributed variable and either the sample size is small or the variable’s standard deviation is unknown. Essentially, the <span class="math inline">\(t\)</span> distribution increases the uncertainty (i.e., variance) in cases of low sample size (i.e., small <span class="math inline">\(n\)</span>). With low sample size (and/or high number of parameters), the degrees of freedom of the <span class="math inline">\(t\)</span>-distribution, <span class="math inline">\(\nu\)</span> is low, whereas with high sample size, <span class="math inline">\(\nu\)</span> is large. As <span class="math inline">\(\nu\)</span> approaches infinity, the <span class="math inline">\(t\)</span>-distribution approximates the standard normal distribution (i.e., <span class="math inline">\(N(\mu, \sigma)|\mu=0,\sigma=1\)</span>).</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>It is the case for <span class="math inline">\(\hat{B} \sim N \left( B, (X^TX)^{-1} \hat{\sigma}^2 \right)\)</span> that we do not know the mean (<span class="math inline">\(B\)</span>), and we are estimating the variance, <span class="math inline">\(\hat{\sigma}^2\)</span>. Specifically, we are estimating the true mean vector, <span class="math inline">\(B\)</span>, as <span class="math inline">\(\hat{B}\)</span>, and we are estimating the variance of the residuals as <span class="math inline">\(\hat{\sigma}^2\)</span>. We can therefore re-write the uncertainty in <span class="math inline">\(\hat{B}\)</span> as a multivariate <span class="math inline">\(t\)</span> distribution: <span class="math display">\[(\hat{B} - B) \sim t_{\nu} \left( 0, \Sigma \right),\]</span> where the means are zero, <span class="math inline">\(\nu\)</span> is the degrees of freedom (i.e., <span class="math inline">\(n-p\)</span>), and <span class="math inline">\(\Sigma = (X^TX)^{-1} \hat{\sigma}^2\)</span>. <span class="math inline">\((\hat{B} - B)\)</span> represents the deviation of the estimated coefficients from the true coefficients, which is why the distribution is centered around zero. It is perhaps easier to separate the individual estimated coefficients, <span class="math inline">\(\beta_i\)</span>, into their separate <span class="math inline">\(t\)</span>-distributions: <span class="math display">\[\frac{(\hat{\beta}_i - \beta_i)}{SE(\hat{\beta}_i)} \sim t_{\nu}\]</span> <span class="math display">\[(\hat{\beta}_i - \beta_i) \sim t_{\nu} SE(\hat{\beta}_i),\]</span> which shows that the <span class="math inline">\(t\)</span>-distribution that describes the deviation of regression coefficients from the true value of those coefficients is scaled by the uncertainty in the estimated coefficients <span class="math inline">\(SE(\hat{\beta}_i)\)</span>. As shown in Dr.&nbsp;Barber’s materials, using this information, we can derive the confidence interval (at the <span class="math inline">\(\alpha\)</span> confidence level) calculation for <span class="math inline">\(\hat{\beta}_i\)</span> as: <span class="math display">\[ \hat{\beta}_i \pm t \left(\frac{1-\alpha}{2}, \nu \right) SE(\hat{\beta}_i),\]</span> where the <span class="math inline">\(t()\)</span> notation represents the <em>critical value</em> of the <span class="math inline">\(t\)</span>-distribution, <span class="math inline">\(t_{crit}\)</span>, with <span class="math inline">\(\nu\)</span> degrees of freedom, for which <span class="math inline">\(P(z \le t_{crit}) = \frac{1-\alpha}{2}\)</span>, and <span class="math inline">\(z\)</span> is a continuous, random variable. This critical value can be calculated in R using the <code><a href="https://rdrr.io/r/stats/TDist.html">qt()</a></code> function, which we show below.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Covariance of <span class="math inline">\(\hat{\beta}_i\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Although it is convenient and easier to digest the confidence interval of individual <span class="math inline">\(\hat{\beta}_i\)</span>, we must realize that the estimates of the <span class="math inline">\(\beta_i\)</span> can covary (i.e., have non-zero covariance), which is quantified in the variance-covariance matrix of <span class="math inline">\(\hat{B}\)</span>, <span class="math inline">\((X^TX)^{-1} \hat{\sigma}^2\)</span>. We will show why this is important below.</p>
</div>
</div>
<p>Let’s manually calculate the 95% confidence intervals in <span class="math inline">\(\hat{B}\)</span> and compare to R’s internal function <code><a href="https://rdrr.io/r/stats/confint.html">confint()</a></code>.</p>
<div class="cell">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract the degrees of freedom from the model (\nu)</span></span>
<span><span class="co"># which can also be calculated as n - p</span></span>
<span><span class="va">t_df</span> <span class="op">=</span> <span class="va">lm_out</span><span class="op">$</span><span class="va">df.residual</span></span>
<span></span>
<span><span class="co"># Calculate t critical for alpha = 0.05</span></span>
<span><span class="co"># This will give us the 95% conf interval (CI)</span></span>
<span><span class="va">t_crit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="op">(</span><span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span>, df <span class="op">=</span> <span class="va">t_df</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate the upper and lower CI for both betas</span></span>
<span><span class="va">ci_int</span> <span class="op">=</span> <span class="va">lm_coef</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">t_crit</span><span class="op">*</span><span class="va">se_beta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">ci_slope</span> <span class="op">=</span> <span class="va">lm_coef</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">t_crit</span><span class="op">*</span><span class="va">se_beta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Construct a table of values</span></span>
<span><span class="va">ci_mat</span> <span class="op">=</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">lm_coef</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">ci_int</span><span class="op">)</span>,</span>
<span>          <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">lm_coef</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">ci_slope</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">ci_mat</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"coef"</span>, <span class="st">"lowCI"</span>, <span class="st">"highCI"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">ci_mat</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"intercept"</span>, <span class="st">"slope"</span><span class="op">)</span></span>
<span><span class="va">ci_mat</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              coef     lowCI    highCI
intercept 5.771429 -3.048956 14.591813
slope     1.628571 -1.196212  4.453355</code></pre>
</div>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compare these manual calculations to built-in</span></span>
<span><span class="co"># function confint(), which by default extracts the </span></span>
<span><span class="co"># 95% CI for a lm() model's coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">lm_out</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                2.5 %    97.5 %
(Intercept) -3.048956 14.591813
x1          -1.196212  4.453355</code></pre>
</div>
</div>
</section><section id="propagate-uncertainty-in-hatb-for-predictions-of-y" class="level2" data-number="4.10"><h2 data-number="4.10" class="anchored" data-anchor-id="propagate-uncertainty-in-hatb-for-predictions-of-y">
<span class="header-section-number">4.10</span> Propagate uncertainty in <span class="math inline">\(\hat{B}\)</span> for predictions of <span class="math inline">\(Y\)</span>
</h2>
<p>There are several ways to calculate and visualize our uncertainty in model predictions of observed data <span class="math inline">\(Y\)</span> and unobserved data of the dependent variable (i.e., interpolation). The colored lines drawn on the figure in <a href="#sec-est-plot"><span>Section&nbsp;4.6</span></a> represent the expected values of <span class="math inline">\(Y\)</span> based on the OLS analysis’ estimate of <span class="math inline">\(\hat{B}\)</span>, but this line does not include uncertainty in these coefficient values.</p>
<section id="multivariate-t-distribution-method" class="level3" data-number="4.10.1"><h3 data-number="4.10.1" class="anchored" data-anchor-id="multivariate-t-distribution-method">
<span class="header-section-number">4.10.1</span> Multivariate <span class="math inline">\(t\)</span>-distribution method</h3>
<p>First, we will calculate uncertainty by sampling from the multivariate <span class="math inline">\(t\)</span> distribution that represents error in regression coefficients, <span class="math inline">\(\hat{B}\)</span>.</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># We will "bootstrap" 1000 samples of intercept and slope</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">n_samp</span> <span class="op">=</span> <span class="fl">500</span></span>
<span></span>
<span><span class="co"># Draw from the multivariate t </span></span>
<span><span class="co"># which represents (\hat{B} - B)</span></span>
<span><span class="va">test_mat_deviates</span> <span class="op">=</span> </span>
<span>  <span class="fu">mnormt</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/mnormt/man/mt.html">rmt</a></span><span class="op">(</span><span class="va">n_samp</span>, mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">0</span><span class="op">)</span>, S <span class="op">=</span> <span class="va">beta_cov_mat</span>, df <span class="op">=</span> <span class="va">t_df</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Now calculate the realized intercept and slope</span></span>
<span><span class="co"># using the t-distributed deviates</span></span>
<span><span class="va">test_mat_t</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span></span>
<span>  <span class="va">lm_coef</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">test_mat_deviates</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  <span class="va">lm_coef</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">test_mat_deviates</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate the 95% quantiles and compare to the </span></span>
<span><span class="co"># calculated 95% confidence intervals from above</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">test_mat_t</span>, </span>
<span>      MARGIN <span class="op">=</span> <span class="fl">2</span>, <span class="co"># applies function (FUN) to columns (dim 2)</span></span>
<span>      FUN <span class="op">=</span> <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]       [,2]
2.5%  -3.820226 -0.5319227
50%    5.809501  1.5967318
97.5% 13.564890  4.1240734</code></pre>
</div>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compare</span></span>
<span><span class="va">ci_mat</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              coef     lowCI    highCI
intercept 5.771429 -3.048956 14.591813
slope     1.628571 -1.196212  4.453355</code></pre>
</div>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot the relationship between intercept and slope</span></span>
<span><span class="co"># Notice the covariance</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">test_mat_t</span>, xlab <span class="op">=</span> <span class="st">"Intercept"</span>, ylab <span class="op">=</span> <span class="st">"Slope"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Next, for each pair of intercept and slope randomly drawn above, we will calculate the expected values of <span class="math inline">\(Y\)</span> across the range of covariate <span class="math inline">\(x\)</span>. We will then summarize the 95% quantile of expected <span class="math inline">\(Y\)</span> at each value of <span class="math inline">\(x\)</span> in this interpolation. To do this, we need a function to calculate the expected value of <span class="math inline">\(Y\)</span>. This function will have the intercept and slope as inputs and will output the expected values of <span class="math inline">\(Y\)</span> across a range of <span class="math inline">\(x\)</span>. Then, we will <code><a href="https://rdrr.io/r/base/apply.html">apply()</a></code> this function using all of the values of intercept and slope, in a vectorized and therefore very efficient manner, rather than using any <code>for</code> loops.</p>
<div class="cell">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a matrix that holds the values of x</span></span>
<span><span class="co"># over which we want to interpolate the expected</span></span>
<span><span class="co"># values of Y</span></span>
<span><span class="va">x_fake_mat</span> <span class="op">=</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, times <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span>,length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a function that will calculate the expected values</span></span>
<span><span class="va">y_hat_fun</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">x_mat</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">x_mat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">x</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Apply this function to all intercepts and slopes that</span></span>
<span><span class="co"># we drew from the multivariate t</span></span>
<span><span class="va">y_pred_mt</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">test_mat_t</span>, <span class="fl">1</span>, <span class="va">y_hat_fun</span>, x_mat<span class="op">=</span><span class="va">x_fake_mat</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summarize the 95% quantile of the expected value of Y</span></span>
<span><span class="co"># at each value of x </span></span>
<span><span class="va">y_pred_mt_summary</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">y_pred_mt</span>, <span class="fl">1</span>, <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">y_pred_mt_summary</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:2, 1:100] -3.82 13.56 -3.62 13.58 -3.41 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:2] "2.5%" "97.5%"
  ..$ : NULL</code></pre>
</div>
</div>
</section><section id="predict-function-method" class="level3" data-number="4.10.2"><h3 data-number="4.10.2" class="anchored" data-anchor-id="predict-function-method">
<span class="header-section-number">4.10.2</span> <code>predict()</code> function method</h3>
<p>R has a built-in function <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> (see specific variant <code><a href="https://rdrr.io/r/stats/predict.lm.html">predict.lm()</a></code>) which calculates expected values of the dependent variable from a linear regression model estimated using the function <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>.</p>
<div class="cell">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Note that 'newdata' must be a data frame that includes the ranges</span></span>
<span><span class="co"># of each covariate in the regression model for which you want </span></span>
<span><span class="co"># to generate interpolated or predicted values of the dependent variable</span></span>
<span></span>
<span><span class="co"># Here we are calculated the expected values as well as the </span></span>
<span><span class="co"># 95% confidence intervals for those expected values</span></span>
<span><span class="va">y_predict</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lm_out</span>,</span>
<span>                 newdata <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x_fake_mat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                 interval <span class="op">=</span> <span class="st">"confidence"</span>, level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">y_predict</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:100, 1:3] 5.77 5.85 5.94 6.02 6.1 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:100] "1" "2" "3" "4" ...
  ..$ : chr [1:3] "fit" "lwr" "upr"</code></pre>
</div>
</div>
</section><section id="compare-the-two-methods" class="level3" data-number="4.10.3"><h3 data-number="4.10.3" class="anchored" data-anchor-id="compare-the-two-methods">
<span class="header-section-number">4.10.3</span> Compare the two methods</h3>
<p>Let’s visualize the output of the two methods to compare.</p>
<div class="cell">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span>x<span class="op">=</span><span class="cn">NA</span>,y<span class="op">=</span><span class="cn">NA</span>,xlab <span class="op">=</span> <span class="st">"x"</span>, ylab <span class="op">=</span> <span class="st">"y"</span>,</span>
<span>     xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">25</span><span class="op">)</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span>
<span><span class="co"># Plot the expected values of Y for each pair of int/slope </span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_samp</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">y_pred_mt</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="va">x_fake_mat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>,</span>
<span>        <span class="co"># Reduce the opacity of each line</span></span>
<span>        col <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/alpha.html">alpha</a></span><span class="op">(</span><span class="st">"black"</span>, alpha <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="co"># Add the data points</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span>, col <span class="op">=</span> <span class="st">'orange'</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co"># Add the expected values of Y from \hat{B}</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>coef <span class="op">=</span> <span class="va">lm_coef</span>, col <span class="op">=</span> <span class="st">"orange"</span>, lwd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co"># Add the conf int of expected Y using multivariate t</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">y_pred_mt_summary</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> <span class="op">~</span> <span class="va">x_fake_mat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, lty <span class="op">=</span> <span class="fl">2</span>, lwd <span class="op">=</span> <span class="fl">3</span>, col <span class="op">=</span> <span class="st">"orange"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">y_pred_mt_summary</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> <span class="op">~</span> <span class="va">x_fake_mat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, lty <span class="op">=</span> <span class="fl">2</span>, lwd <span class="op">=</span> <span class="fl">3</span>, col <span class="op">=</span> <span class="st">"orange"</span><span class="op">)</span></span>
<span><span class="co"># Add the conf int of expected Y using predict() function</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">y_predict</span><span class="op">[</span>,<span class="st">"lwr"</span><span class="op">]</span><span class="op">~</span> <span class="va">x_fake_mat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, lty <span class="op">=</span> <span class="fl">3</span>, lwd <span class="op">=</span> <span class="fl">3</span>, col <span class="op">=</span> <span class="st">"purple"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">y_predict</span><span class="op">[</span>,<span class="st">"upr"</span><span class="op">]</span><span class="op">~</span> <span class="va">x_fake_mat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, lty <span class="op">=</span> <span class="fl">3</span>, lwd <span class="op">=</span> <span class="fl">3</span>, col <span class="op">=</span> <span class="st">"purple"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>There is yet a third option to calculate the uncertainty in predicted (i.e., interpolated or extrapolated) values of <span class="math inline">\(Y\)</span>, which is to derive an exact calculation of the confidence interval using the <span class="math inline">\(t\)</span> distribution, similar to that shown in <a href="#sec-conf-beta"><span>Section&nbsp;4.9</span></a>. See Ch4.1 of Dr.&nbsp;Barber’s book for this derivation.</p>
</section></section><section id="multiple-linear-regression" class="level2" data-number="4.11"><h2 data-number="4.11" class="anchored" data-anchor-id="multiple-linear-regression">
<span class="header-section-number">4.11</span> Multiple Linear Regression</h2>
<p>So far, we have only discussed a single input variable in our model, which is a simple linear regression. When we have multiple input variables, we are dealing with multiple linear regression analysis, so the model looks like: <span class="math display">\[y_i = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \dots + \beta_{p-1} x_{p-1,i} + \epsilon_i\]</span> where <span class="math inline">\(p\)</span> is the number of model coefficients and <span class="math inline">\(p-1\)</span> is the number of input variables. Still, in matrix notation the model is <span class="math inline">\(Y = XB + \epsilon\)</span>, so the least squares regression analysis approach still works. However, our interpretation of the model coefficients becomes a bit more challenging.</p>
<p>Let’s look at a data set within the <code>faraway</code> package.</p>
<div class="cell">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/julianfaraway/faraway">faraway</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">gala</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the raw data relationships</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">gala</span><span class="op">$</span><span class="va">Species</span> <span class="op">~</span> <span class="va">gala</span><span class="op">$</span><span class="va">Elevation</span>, xlab <span class="op">=</span> <span class="st">"Elevation"</span>, ylab <span class="op">=</span> <span class="st">"Species"</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">gala</span><span class="op">$</span><span class="va">Species</span> <span class="op">~</span> <span class="va">gala</span><span class="op">$</span><span class="va">Area</span>, xlab <span class="op">=</span> <span class="st">"Area"</span>, ylab <span class="op">=</span> <span class="st">"Species"</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">gala</span><span class="op">$</span><span class="va">Species</span> <span class="op">~</span> <span class="va">gala</span><span class="op">$</span><span class="va">Adjacent</span>, xlab <span class="op">=</span> <span class="st">"Adjacent"</span>, ylab <span class="op">=</span> <span class="st">"Species"</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid" width="768"></p>
</div>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Conduct multiple and single linear regressionm, focusing on Elevation</span></span>
<span><span class="va">m1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">~</span> <span class="va">Elevation</span> <span class="op">+</span> <span class="va">Area</span> <span class="op">+</span> <span class="va">Adjacent</span>, data <span class="op">=</span> <span class="va">gala</span><span class="op">)</span></span>
<span><span class="va">m2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">~</span> <span class="va">Elevation</span>, data <span class="op">=</span> <span class="va">gala</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span>; <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)   Elevation        Area    Adjacent 
-5.71892681  0.31498110 -0.02031217 -0.07527974 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)   Elevation 
 11.3351132   0.2007922 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">gala</span><span class="op">$</span><span class="va">Species</span> <span class="op">~</span> <span class="va">gala</span><span class="op">$</span><span class="va">Elevation</span>, xlab <span class="op">=</span> <span class="st">"Elevation"</span>, ylab <span class="op">=</span> <span class="st">"Species"</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>coef<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>coef<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m2</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>What we see above is how the addition of <code>Area</code> and <code>Adjacent</code> input variables into the model “adjusts” the effect of <code>Elevation</code>, leading to two unique estimates of the slope (i.e., effect) of <code>Elevation</code>. Let’s probe multiple linear regression more closely by using simulated data.</p>
<p>First, let’s simulate a model with 80 data points that correspond to observations of 4 input variables and one outcome variable. Note that in <a href="#sec-mlr">Footnotes&nbsp;<span>4.12.3</span></a>, we show a case with a categorical/binary input variable.</p>
<div class="cell">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">n</span> <span class="op">=</span> <span class="fl">80</span></span>
<span><span class="va">n_covariate</span> <span class="op">=</span> <span class="fl">4</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="va">n_covariate</span> <span class="op">+</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">betas</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span><span class="st">"numeric"</span>, length <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">xmat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fl">0</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">sigma</span> <span class="op">=</span> <span class="fl">2.25</span></span>
<span></span>
<span><span class="co"># Column for intercept</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="co"># Generate the covariate data randomly:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">5</span>, sd <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq</a></span><span class="op">(</span><span class="va">n</span>, df <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span><span class="va">n</span>, lambda <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">p</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">xmat</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span>, main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"covariate "</span>, <span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-32-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Set the betas:</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1.0</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="fl">0.75</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="op">-</span><span class="fl">1.2</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1.8</span></span>
<span></span>
<span><span class="co"># Calculate the observed 'y', adding residual error</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-32-2.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">p</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">xmat</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span>,</span>
<span>         xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"covariate "</span>, <span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-32-3.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>How do we figure out the expected value of <span class="math inline">\(y\)</span> for a particular situation? Here’s an example. What is the expected value of <span class="math inline">\(y\)</span> when <span class="math inline">\(x_2 = 0.5\)</span>, but the rest of the input variables are at their average values?</p>
<div class="cell">
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Written out long-ways:</span></span>
<span><span class="va">pred_y</span> <span class="op">=</span> </span>
<span>    <span class="va">betas</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">*</span><span class="fl">1</span> <span class="op">+</span> </span>
<span>    <span class="va">betas</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="va">betas</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">*</span><span class="fl">0.5</span> <span class="op">+</span> </span>
<span>    <span class="va">betas</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">4</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="va">betas</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">5</span><span class="op">]</span><span class="op">)</span> </span>
<span><span class="va">pred_y</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 22.6006</code></pre>
</div>
</div>
<p>Now let’s use ordinary least squares regression to estimate our model coefficients from the data, and then compare these to our “known” values of the model parameters.</p>
<div class="cell">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Run the model:</span></span>
<span><span class="va">m1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">xmat</span><span class="op">)</span></span>
<span><span class="co"># Note that the following two models give the same results</span></span>
<span><span class="co">#m2 = lm(y ~ 0 + X1 + X2 + X3 + X4 + X5, data = data.frame(xmat))</span></span>
<span><span class="co">#m3 = lm(y ~ 1 + X2 + X3 + X4 + X5, data = data.frame(xmat))</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ 0 + xmat)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.4388 -1.4712  0.2816  1.5305  5.0032 

Coefficients:
       Estimate Std. Error t value Pr(&gt;|t|)    
xmat1  1.589838   1.759860   0.903    0.369    
xmat2  0.737086   0.035629  20.688   &lt;2e-16 ***
xmat3 -1.295274   0.044252 -29.270   &lt;2e-16 ***
xmat4 -0.003676   0.028481  -0.129    0.898    
xmat5  1.826125   0.088971  20.525   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.388 on 75 degrees of freedom
Multiple R-squared:  0.9763,    Adjusted R-squared:  0.9747 
F-statistic: 616.7 on 5 and 75 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#summary(m2)</span></span>
<span><span class="co">#summary(m3)</span></span>
<span></span>
<span><span class="co"># Compare known `betas` to estimated coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">betas</span>, <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      betas             
xmat1  1.00  1.589837527
xmat2  0.75  0.737085861
xmat3 -1.20 -1.295274007
xmat4  0.00 -0.003676167
xmat5  1.80  1.826125438</code></pre>
</div>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot the regression lines with abline</span></span>
<span><span class="va">coef_m1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">p</span><span class="op">)</span><span class="op">{</span></span>
<span>    </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">xmat</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span>, pch<span class="op">=</span><span class="fl">19</span>,</span>
<span>         xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"covariate "</span>, <span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>         ylab <span class="op">=</span> <span class="st">"y"</span>,</span>
<span>         ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>coef<span class="op">=</span><span class="va">coef_m1</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="va">i</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-36-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Well, those regression lines do not look correct. That is because we are interpretting the slopes and intercepts a little incorrectly and not plotting them in the correct manner.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
How to plot the output of <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> for multiple linear regression
</div>
</div>
<div class="callout-body-container callout-body">
<p>When we isolate and visualize the relationship between the outcome and a single input variable, what we are really observing is the adjusted relationship, after accounting for the other input variables in the model. To understand the expected value of <span class="math inline">\(y\)</span> for any particular value of the single input variable, we really need to set the other input variables to their mean value. Let’s demonstrate this below with the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function.</p>
</div>
</div>
<p>Let’s determine the expected values of <span class="math inline">\(y\)</span> for input variable 2 (<span class="math inline">\(x_2\)</span>) and plot it.</p>
<div class="cell">
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Prediction for covariate 2 when all other input vars at mean</span></span>
<span><span class="va">my_df</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">my_df</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          X1         X2       X3 X4
1 -1.7268438 13.8180926 61.27634  8
2 16.0748747  6.7393185 58.15099 14
3 -5.0439349  0.8145552 36.82198 16
4  5.5611421 18.1722388 38.24042 10
5 18.6915270 16.7070212 51.91376 15
6  0.1767361 12.9778881 45.11988 16</code></pre>
</div>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Re-run the model but with just the input variables, </span></span>
<span><span class="co"># and the intercept is implicit</span></span>
<span><span class="va">m2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">X1</span> <span class="op">+</span> <span class="va">X2</span> <span class="op">+</span> <span class="va">X3</span> <span class="op">+</span> <span class="va">X4</span>, data <span class="op">=</span> <span class="va">my_df</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Now let's try to predict y across a range of </span></span>
<span><span class="co"># input variable 2,</span></span>
<span><span class="co"># while holding the other input variables at</span></span>
<span><span class="co"># their average values</span></span>
<span></span>
<span><span class="va">n_pred</span> <span class="op">=</span> <span class="fl">100</span></span>
<span><span class="va">new_df</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  X1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">my_df</span><span class="op">$</span><span class="va">X1</span><span class="op">)</span>, <span class="va">n_pred</span><span class="op">)</span>,</span>
<span>  X2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">20</span>, length.out <span class="op">=</span> <span class="va">n_pred</span><span class="op">)</span>,</span>
<span>  X3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">my_df</span><span class="op">$</span><span class="va">X3</span><span class="op">)</span>, <span class="va">n_pred</span><span class="op">)</span>,</span>
<span>  X4 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">my_df</span><span class="op">$</span><span class="va">X4</span><span class="op">)</span>, <span class="va">n_pred</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">y_pred2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">m2</span>, newdata <span class="op">=</span> <span class="va">new_df</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Now plot:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">my_df</span><span class="op">$</span><span class="va">X2</span>, pch <span class="op">=</span> <span class="fl">19</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"covariate 2"</span>, ylab <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">y_pred2</span> <span class="op">~</span> <span class="va">new_df</span><span class="op">$</span><span class="va">X2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-38-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Now we see that the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function shows a more intuitive relationship between input variable <span class="math inline">\(x_2\)</span> and outcome <span class="math inline">\(y\)</span>, <em>while accounting for the effects of the three other input variables</em>.</p>
</section><section id="footnotes" class="level2" data-number="4.12"><h2 data-number="4.12" class="anchored" data-anchor-id="footnotes">
<span class="header-section-number">4.12</span> Footnotes</h2>
<section id="sec-crossprod" class="level3" data-number="4.12.1"><h3 data-number="4.12.1" class="anchored" data-anchor-id="sec-crossprod">
<span class="header-section-number">4.12.1</span> Euclidean norm &amp; cross product</h3>
<p>We often see the syntax, <span class="math inline">\(|| a ||\)</span>, which is the Euclidean norm of the <span class="math inline">\(n\)</span>-sized vector <span class="math inline">\(a\)</span>: <span class="math display">\[|| a || = \left( \sum_{i=1}^{n} a_i^2 \right) ^ {1/2} ,\]</span> so that when we see <span class="math inline">\(|| a ||^2\)</span>, this results in the sum of squares of vector <span class="math inline">\(a\)</span>, <span class="math inline">\(\sum_{i=1}^{n} a_i^2\)</span>.</p>
<p>In the context of least squares regression, we are trying to minimize the residual sum of squares, where the residuals, <span class="math inline">\(\epsilon_i\)</span>, are in vector, <span class="math inline">\(\epsilon\)</span>. The sum of squares of vector <span class="math inline">\(\epsilon\)</span> is therefore <span class="math inline">\(|| \epsilon ||^2\)</span>. Algebraically, we can find this value as the cross product of <span class="math inline">\(\epsilon\)</span>, which is <span class="math inline">\(\epsilon^{T}\epsilon\)</span>. Let’s do a coded example with vector <span class="math inline">\(x\)</span>.</p>
<div class="cell">
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Vector of real numbers</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># sum of squares</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 30</code></pre>
</div>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Evaluated as cross-product</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">x</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]   30</code></pre>
</div>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Or with crossprod()</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/crossprod.html">crossprod</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">x</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]   30</code></pre>
</div>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Euclidean norm also known as the 2-norm</span></span>
<span><span class="co"># so sum of squares is 2-norm, squared</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/norm.html">norm</a></span><span class="op">(</span><span class="va">x</span>, type <span class="op">=</span> <span class="st">"2"</span><span class="op">)</span> <span class="op">^</span> <span class="fl">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 30</code></pre>
</div>
</div>
</section><section id="sec-solve" class="level3" data-number="4.12.2"><h3 data-number="4.12.2" class="anchored" data-anchor-id="sec-solve">
<span class="header-section-number">4.12.2</span> <code>solve()</code> and Inverse of matrix</h3>
<p>Suppose we have matrices <span class="math inline">\(A\)</span>, <span class="math inline">\(X\)</span>, and <span class="math inline">\(B\)</span>, and the following expression is true: <span class="math display">\[AX=B.\]</span></p>
<p>Then, suppose <span class="math inline">\(X\)</span> is unknown, such that we want to find the solution for <span class="math inline">\(X\)</span>, when we rearrange: <span class="math display">\[X = A^{-1} B,\]</span> where <span class="math inline">\(A^{-1}\)</span> is the multiplicative inverse of matrix <span class="math inline">\(A\)</span>. To figure this out computationally, we can use the <code><a href="https://rdrr.io/r/base/solve.html">solve()</a></code> function in R, as long as <span class="math inline">\(A\)</span> is a square matrix and has an inverse.</p>
<div class="cell">
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create A and known X</span></span>
<span><span class="va">A</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">1</span>,</span>
<span>             <span class="fl">5</span>,<span class="fl">2</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Dot product to calculate B</span></span>
<span><span class="va">B</span> <span class="op">=</span> <span class="va">A</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">X</span></span>
<span></span>
<span><span class="co"># Suppose you have A and B, but want to find X</span></span>
<span><span class="va">X_solve</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="va">A</span>, <span class="va">B</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Did it work?</span></span>
<span><span class="va">X</span>; <span class="va">X_solve</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]    2
[2,]    3</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]    2
[2,]    3</code></pre>
</div>
</div>
<p>We can see, then, that <code><a href="https://rdrr.io/r/base/solve.html">solve()</a></code> is internally evaluating <span class="math inline">\(A^{-1}\)</span>. Remember that <span class="math inline">\(A^{-1}\)</span> is not trivial to calculate, as it is the matrix that must satisfy: <span class="math inline">\(AA^{-1} = I\)</span>, where <span class="math inline">\(I\)</span> is an identity matrix. In fact, <code>solve(A)</code> returns the inverse of <span class="math inline">\(A\)</span>, if it exists.</p>
<div class="cell">
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inv_A</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="va">A</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#Did it work?</span></span>
<span><span class="op">(</span><span class="va">inv_A</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">B</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]    2
[2,]    3</code></pre>
</div>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">X</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]    2
[2,]    3</code></pre>
</div>
</div>
</section><section id="sec-mlr" class="level3" data-number="4.12.3"><h3 data-number="4.12.3" class="anchored" data-anchor-id="sec-mlr">
<span class="header-section-number">4.12.3</span> Multiple linear regression with a categorical input</h3>
<p>Let’s simulate a case in which we have one categorical input variable that takes on values “low”, “medium”, and “high”, and one continuous input variable.</p>
<div class="cell">
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">7</span><span class="op">)</span></span>
<span><span class="va">n</span><span class="op">=</span><span class="fl">90</span></span>
<span><span class="va">sigma</span> <span class="op">=</span> <span class="fl">0.8</span></span>
<span></span>
<span><span class="co"># Xmatrix</span></span>
<span><span class="co">## Intercept</span></span>
<span><span class="va">x0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, times <span class="op">=</span> <span class="va">n</span><span class="op">)</span> </span>
<span><span class="co">## Categorical input variable</span></span>
<span><span class="co">### Note that we need to code this as "0" "1" "2" to </span></span>
<span><span class="co">### simulate our outcome variable "y"</span></span>
<span><span class="va">x1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span>, each<span class="op">=</span><span class="va">n</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">x1L</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">x1</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"low"</span>, <span class="st">"med"</span>, <span class="st">"high"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## Continuous input variable</span></span>
<span><span class="va">x2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">0</span>, <span class="fl">2.5</span><span class="op">)</span></span>
<span><span class="va">xmat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">x0</span>,<span class="va">x1</span>,<span class="va">x2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">xmat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     x0 x1        x2
[1,]  1  0  5.718118
[2,]  1  0 -2.991929
[3,]  1  0 -1.735731
[4,]  1  0 -1.030732
[5,]  1  0 -2.426683
[6,]  1  0 -2.368200</code></pre>
</div>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Intercept and 2 slopes</span></span>
<span><span class="va">betas</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1.5</span>, <span class="fl">1.2</span>, <span class="op">-</span><span class="fl">1.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate outcome variable, as usual</span></span>
<span><span class="va">y2</span> <span class="op">=</span> <span class="va">xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>,<span class="fl">0</span>,<span class="va">sigma</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the relationships</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">y2</span><span class="op">~</span><span class="va">x1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">y2</span><span class="op">~</span><span class="va">x2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="ols_files/figure-html/unnamed-chunk-46-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Run the model</span></span>
<span><span class="co">## Note that we us the "factor" input variable</span></span>
<span><span class="co">## "x1L", which has "levels"</span></span>
<span><span class="va">m_cat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y2</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">x1L</span> <span class="op">+</span> <span class="va">x2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m_cat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y2 ~ 1 + x1L + x2)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.9182 -0.5032  0.1465  0.5061  1.2139 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.66504    0.13741  12.117  &lt; 2e-16 ***
x1Lmed       1.15971    0.19113   6.068 3.38e-08 ***
x1Lhigh      2.29169    0.19170  11.954  &lt; 2e-16 ***
x2          -1.51229    0.03275 -46.171  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.7314 on 86 degrees of freedom
Multiple R-squared:  0.9674,    Adjusted R-squared:  0.9663 
F-statistic: 851.1 on 3 and 86 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m_cat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)      x1Lmed     x1Lhigh          x2 
   1.665040    1.159710    2.291690   -1.512293 </code></pre>
</div>
</div>
<p>How do we interpret the slopes, because we see there is a separate slope for <code>x1Lmed</code> and <code>x1Lhigh</code>? We can understand better by seeing how the linear model addes up. For instance, what is the expected value of the outcome variable when <span class="math inline">\(x_1\)</span> is <code>high</code>, and <span class="math inline">\(x_2 = 2.0\)</span>?</p>
<div class="cell">
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Using m1_binL:</span></span>
<span><span class="va">y2_pred</span> <span class="op">=</span> </span>
<span>    <span class="fl">1</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m_cat</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="co"># Global average (intercept)</span></span>
<span>    <span class="fl">0</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m_cat</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="co"># Not "med"</span></span>
<span>    <span class="fl">1</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m_cat</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="co"># Yes "high"</span></span>
<span>    <span class="fl">2.0</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m_cat</span><span class="op">)</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span> <span class="co"># x2=2.0 * slope</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">y2_pred</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9321446</code></pre>
</div>
</div>
<p>When we assigned the slope of the categorical input variable as <span class="math inline">\(1.2\)</span>, remember this is the expected change in <span class="math inline">\(y\)</span> as the input variable changes by a value of <span class="math inline">\(1.0\)</span>. In the model, we code the <span class="math inline">\(x_1\)</span> variable as taking numerical values <span class="math inline">\(0\)</span>, <span class="math inline">\(1\)</span>, and <span class="math inline">\(2\)</span> to represent categories, “low”, “medium”, and “high”. So, the slope for <code>x1med</code> is the expected change in <span class="math inline">\(y\)</span> as the input variable changes from “low” to “medium”, an effective change of <span class="math inline">\(1.0\)</span>. Then, the slope for <code>x1high</code> is the expected change in <span class="math inline">\(y\)</span> as the input variable changes from “low” to “high”, an effective change of <span class="math inline">\(2.0\)</span>; hence, this slope is estimated as <span class="math inline">\(2.29\)</span>, with standard error <span class="math inline">\(0.19\)</span>. Notice how this slope is approximately twice our “known” slope for the input variable, which was <span class="math inline">\(1.2\)</span>.</p>


<!-- -->

</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./prob.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability distributions</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./hypothesis.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb81" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Ordinary Least Squares {#sec-ols}</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="fu">## Lecture material</span></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>Please download and print the lecture materials from <span class="co">[</span><span class="ot">Bblearn</span><span class="co">](https://bblearn.nau.edu/)</span>{target="_blank"}. After lectures, the recordings will appear in the Bblearn Collaborate Ultra section.</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## In-class Code {.unnumbered}</span></span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>Remember that our goal is to estimate the linear relationship between data observations of response variable, $y$, and its measured covariate, $x$, following: $Y = XB + \epsilon$, where $\epsilon \sim N(0, \sigma^2 I).$ Our coefficients to estimate are therefore $\hat{B}$, which is a column vector of the intercept and slope. We also estimate the standard deviation of the residuals (i.e., residual error), $\hat{\sigma}$. To estimate the coefficients, we are attempting to minimize the residual sum of squares, $|| \epsilon || ^ 2$. See <span class="co">[</span><span class="ot">Footnotes @sec-crossprod</span><span class="co">]</span> for more information regarding this notation.</span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## Generate the data</span></span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>We'll start with a very small data set to emphasize the basics, and then the in-class activity will go into more depth. Here, we'll implement the OLS estimation with a single covariate that we demonstrated in lecture.</span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-17"><a href="#cb81-17" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-18"><a href="#cb81-18" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">4</span> <span class="co"># number observations</span></span>
<span id="cb81-19"><a href="#cb81-19" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="dv">2</span> <span class="co"># number of parameters</span></span>
<span id="cb81-20"><a href="#cb81-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-21"><a href="#cb81-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Covariate:</span></span>
<span id="cb81-22"><a href="#cb81-22" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>) <span class="co"># placeholder for intercept</span></span>
<span id="cb81-23"><a href="#cb81-23" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">1</span>) <span class="co"># value of x</span></span>
<span id="cb81-24"><a href="#cb81-24" aria-hidden="true" tabindex="-1"></a>xmat <span class="ot">=</span> <span class="fu">matrix</span>(<span class="at">data =</span> <span class="fu">c</span>(x0,x1), </span>
<span id="cb81-25"><a href="#cb81-25" aria-hidden="true" tabindex="-1"></a>               <span class="at">nrow =</span> n, </span>
<span id="cb81-26"><a href="#cb81-26" aria-hidden="true" tabindex="-1"></a>               <span class="at">ncol =</span> p)</span>
<span id="cb81-27"><a href="#cb81-27" aria-hidden="true" tabindex="-1"></a>xmat</span>
<span id="cb81-28"><a href="#cb81-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-29"><a href="#cb81-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficients:</span></span>
<span id="cb81-30"><a href="#cb81-30" aria-hidden="true" tabindex="-1"></a><span class="do">## betas[1]: intercept</span></span>
<span id="cb81-31"><a href="#cb81-31" aria-hidden="true" tabindex="-1"></a><span class="do">## betas[2]: slope</span></span>
<span id="cb81-32"><a href="#cb81-32" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb81-33"><a href="#cb81-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-34"><a href="#cb81-34" aria-hidden="true" tabindex="-1"></a>xmat <span class="sc">%*%</span> betas</span>
<span id="cb81-35"><a href="#cb81-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-36"><a href="#cb81-36" aria-hidden="true" tabindex="-1"></a><span class="co"># residuals</span></span>
<span id="cb81-37"><a href="#cb81-37" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb81-38"><a href="#cb81-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-39"><a href="#cb81-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Data observations:</span></span>
<span id="cb81-40"><a href="#cb81-40" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> xmat <span class="sc">%*%</span> betas <span class="sc">+</span> epsilon</span>
<span id="cb81-41"><a href="#cb81-41" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-42"><a href="#cb81-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-43"><a href="#cb81-43" aria-hidden="true" tabindex="-1"></a><span class="fu">## Plot the relationship</span></span>
<span id="cb81-44"><a href="#cb81-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-47"><a href="#cb81-47" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-48"><a href="#cb81-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot in layers</span></span>
<span id="cb81-49"><a href="#cb81-49" aria-hidden="true" tabindex="-1"></a><span class="do">## Create a blank plotting canvas, specifying axis limits</span></span>
<span id="cb81-50"><a href="#cb81-50" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="cn">NA</span>,<span class="at">y=</span><span class="cn">NA</span>, <span class="at">xlab =</span> <span class="st">"x"</span>, <span class="at">ylab =</span> <span class="st">"y"</span>,</span>
<span id="cb81-51"><a href="#cb81-51" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">max</span>(y)), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">max</span>(x1)))</span>
<span id="cb81-52"><a href="#cb81-52" aria-hidden="true" tabindex="-1"></a><span class="do">## Add data points</span></span>
<span id="cb81-53"><a href="#cb81-53" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(y <span class="sc">~</span> x1, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb81-54"><a href="#cb81-54" aria-hidden="true" tabindex="-1"></a><span class="do">## Add known linear relationship</span></span>
<span id="cb81-55"><a href="#cb81-55" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">coef =</span> betas, <span class="at">col =</span> <span class="st">"black"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb81-56"><a href="#cb81-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-57"><a href="#cb81-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the residuals:</span></span>
<span id="cb81-58"><a href="#cb81-58" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> x1, <span class="at">x1 =</span> x1,</span>
<span id="cb81-59"><a href="#cb81-59" aria-hidden="true" tabindex="-1"></a>         <span class="at">y0 =</span> y, <span class="at">y1 =</span> y <span class="sc">-</span> epsilon)</span>
<span id="cb81-60"><a href="#cb81-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-61"><a href="#cb81-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the model predictions, \hat{y}:</span></span>
<span id="cb81-62"><a href="#cb81-62" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">=</span> xmat <span class="sc">%*%</span> betas</span>
<span id="cb81-63"><a href="#cb81-63" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(y_hat <span class="sc">~</span> x1, <span class="at">cex =</span> <span class="fl">1.25</span>)</span>
<span id="cb81-64"><a href="#cb81-64" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-65"><a href="#cb81-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-66"><a href="#cb81-66" aria-hidden="true" tabindex="-1"></a><span class="fu">## Estimate the coefficients using R's `lm()` function {#sec-lm-output}</span></span>
<span id="cb81-67"><a href="#cb81-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-70"><a href="#cb81-70" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-71"><a href="#cb81-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the model:</span></span>
<span id="cb81-72"><a href="#cb81-72" aria-hidden="true" tabindex="-1"></a>lm_out <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x1)</span>
<span id="cb81-73"><a href="#cb81-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the summary output</span></span>
<span id="cb81-74"><a href="#cb81-74" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_out)</span>
<span id="cb81-75"><a href="#cb81-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the estimated coefficients</span></span>
<span id="cb81-76"><a href="#cb81-76" aria-hidden="true" tabindex="-1"></a>lm_coef <span class="ot">=</span> <span class="fu">coef</span>(lm_out)</span>
<span id="cb81-77"><a href="#cb81-77" aria-hidden="true" tabindex="-1"></a>lm_coef</span>
<span id="cb81-78"><a href="#cb81-78" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-79"><a href="#cb81-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-80"><a href="#cb81-80" aria-hidden="true" tabindex="-1"></a><span class="fu">## Estimate the coefficients manually</span></span>
<span id="cb81-81"><a href="#cb81-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-82"><a href="#cb81-82" aria-hidden="true" tabindex="-1"></a>Now we will use the matrix algebra and derivation of normal equations to estimate the intercept and slope from the observations, $Y$. Remember that we estimate the coefficient vector, $\hat{B}$ from: $$X^TX \hat{B} = X^T Y$$ $$\hat{B} = (X^TX)^{-1} X^T Y$$ These equations include the multiplicative inverse matrix, $(X^TX)^{-1}$. See the <span class="co">[</span><span class="ot">Footnotes @sec-solve</span><span class="co">]</span> for more information about inverse matrices and the <span class="in">`solve()`</span> function.</span>
<span id="cb81-83"><a href="#cb81-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-86"><a href="#cb81-86" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-87"><a href="#cb81-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's break up the normal equations into intermediates:</span></span>
<span id="cb81-88"><a href="#cb81-88" aria-hidden="true" tabindex="-1"></a>xtx <span class="ot">=</span> <span class="fu">t</span>(xmat) <span class="sc">%*%</span> xmat</span>
<span id="cb81-89"><a href="#cb81-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-90"><a href="#cb81-90" aria-hidden="true" tabindex="-1"></a><span class="do">## Use solve() to find inverse of xtx</span></span>
<span id="cb81-91"><a href="#cb81-91" aria-hidden="true" tabindex="-1"></a><span class="do">## why solve()? See Appendix, linked above.</span></span>
<span id="cb81-92"><a href="#cb81-92" aria-hidden="true" tabindex="-1"></a>inv_xtx <span class="ot">=</span> <span class="fu">solve</span>(xtx)</span>
<span id="cb81-93"><a href="#cb81-93" aria-hidden="true" tabindex="-1"></a>xty <span class="ot">=</span> <span class="fu">t</span>(xmat) <span class="sc">%*%</span> y</span>
<span id="cb81-94"><a href="#cb81-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-95"><a href="#cb81-95" aria-hidden="true" tabindex="-1"></a>bhat <span class="ot">=</span> inv_xtx <span class="sc">%*%</span> xty</span>
<span id="cb81-96"><a href="#cb81-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-97"><a href="#cb81-97" aria-hidden="true" tabindex="-1"></a><span class="co"># More efficient:</span></span>
<span id="cb81-98"><a href="#cb81-98" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember, xtx * bhat = xty</span></span>
<span id="cb81-99"><a href="#cb81-99" aria-hidden="true" tabindex="-1"></a><span class="co"># So we can use solve() again</span></span>
<span id="cb81-100"><a href="#cb81-100" aria-hidden="true" tabindex="-1"></a>bhat_solve <span class="ot">=</span> <span class="fu">solve</span>(xtx, xty)</span>
<span id="cb81-101"><a href="#cb81-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-102"><a href="#cb81-102" aria-hidden="true" tabindex="-1"></a><span class="co"># Are they the same?</span></span>
<span id="cb81-103"><a href="#cb81-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-104"><a href="#cb81-104" aria-hidden="true" tabindex="-1"></a><span class="co"># How does this manual solution compare to lm()'s solution?</span></span>
<span id="cb81-105"><a href="#cb81-105" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-106"><a href="#cb81-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-107"><a href="#cb81-107" aria-hidden="true" tabindex="-1"></a><span class="fu">## Plot the *estimated* relationships {#sec-est-plot}</span></span>
<span id="cb81-108"><a href="#cb81-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-111"><a href="#cb81-111" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-112"><a href="#cb81-112" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot in layers</span></span>
<span id="cb81-113"><a href="#cb81-113" aria-hidden="true" tabindex="-1"></a><span class="do">## Create a blank plotting canvas, specifying axis limits</span></span>
<span id="cb81-114"><a href="#cb81-114" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NA</span>,<span class="cn">NA</span>,</span>
<span id="cb81-115"><a href="#cb81-115" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"x"</span>, <span class="at">ylab =</span> <span class="st">"y"</span>,</span>
<span id="cb81-116"><a href="#cb81-116" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">max</span>(y)),</span>
<span id="cb81-117"><a href="#cb81-117" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">max</span>(x1)))</span>
<span id="cb81-118"><a href="#cb81-118" aria-hidden="true" tabindex="-1"></a><span class="do">## Add data points</span></span>
<span id="cb81-119"><a href="#cb81-119" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(y <span class="sc">~</span> x1, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb81-120"><a href="#cb81-120" aria-hidden="true" tabindex="-1"></a><span class="do">## Add known linear relationship</span></span>
<span id="cb81-121"><a href="#cb81-121" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">coef =</span> betas,</span>
<span id="cb81-122"><a href="#cb81-122" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"black"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb81-123"><a href="#cb81-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-124"><a href="#cb81-124" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the residuals:</span></span>
<span id="cb81-125"><a href="#cb81-125" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(</span>
<span id="cb81-126"><a href="#cb81-126" aria-hidden="true" tabindex="-1"></a>  <span class="at">x0 =</span> x1,</span>
<span id="cb81-127"><a href="#cb81-127" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> x1,</span>
<span id="cb81-128"><a href="#cb81-128" aria-hidden="true" tabindex="-1"></a>  <span class="at">y0 =</span> y,</span>
<span id="cb81-129"><a href="#cb81-129" aria-hidden="true" tabindex="-1"></a>  <span class="at">y1 =</span> y <span class="sc">-</span> epsilon,</span>
<span id="cb81-130"><a href="#cb81-130" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb81-131"><a href="#cb81-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-132"><a href="#cb81-132" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the model predictions, \hat{y}:</span></span>
<span id="cb81-133"><a href="#cb81-133" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">=</span> xmat <span class="sc">%*%</span> betas</span>
<span id="cb81-134"><a href="#cb81-134" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(y_hat <span class="sc">~</span> x1,</span>
<span id="cb81-135"><a href="#cb81-135" aria-hidden="true" tabindex="-1"></a>       <span class="at">cex =</span> <span class="fl">1.25</span>)</span>
<span id="cb81-136"><a href="#cb81-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-137"><a href="#cb81-137" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the lm() estimate:</span></span>
<span id="cb81-138"><a href="#cb81-138" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">coef =</span> lm_coef,</span>
<span id="cb81-139"><a href="#cb81-139" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"orange"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb81-140"><a href="#cb81-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-141"><a href="#cb81-141" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the manual OLS estimate:</span></span>
<span id="cb81-142"><a href="#cb81-142" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">coef =</span> bhat_solve,</span>
<span id="cb81-143"><a href="#cb81-143" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"purple"</span>, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb81-144"><a href="#cb81-144" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-145"><a href="#cb81-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-146"><a href="#cb81-146" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why are the $\hat{B}$ different from true $B$?</span></span>
<span id="cb81-147"><a href="#cb81-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-148"><a href="#cb81-148" aria-hidden="true" tabindex="-1"></a>Remember, we are estimating the coefficients by minimizing the sum of squared errors (SSE), $|| \epsilon ||^2$.</span>
<span id="cb81-149"><a href="#cb81-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-152"><a href="#cb81-152" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-153"><a href="#cb81-153" aria-hidden="true" tabindex="-1"></a><span class="co"># True sum of squares:</span></span>
<span id="cb81-154"><a href="#cb81-154" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(epsilon)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb81-155"><a href="#cb81-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-156"><a href="#cb81-156" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimated (i.e., minimized sum of squares):</span></span>
<span id="cb81-157"><a href="#cb81-157" aria-hidden="true" tabindex="-1"></a><span class="do">## From lm()</span></span>
<span id="cb81-158"><a href="#cb81-158" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(lm_out<span class="sc">$</span>residuals)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb81-159"><a href="#cb81-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-160"><a href="#cb81-160" aria-hidden="true" tabindex="-1"></a><span class="do">## From manual OLS</span></span>
<span id="cb81-161"><a href="#cb81-161" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>( (y <span class="sc">-</span> xmat <span class="sc">%*%</span> bhat_solve) )<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb81-162"><a href="#cb81-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-163"><a href="#cb81-163" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-164"><a href="#cb81-164" aria-hidden="true" tabindex="-1"></a>You can see that the OLS strategy effectively minimized the SSE to zero.</span>
<span id="cb81-165"><a href="#cb81-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-166"><a href="#cb81-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-167"><a href="#cb81-167" aria-hidden="true" tabindex="-1"></a><span class="fu">## Understanding Uncertainty in $\hat{B}$</span></span>
<span id="cb81-168"><a href="#cb81-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-169"><a href="#cb81-169" aria-hidden="true" tabindex="-1"></a>While the OLS analysis estimates the regression coefficients, $\hat{B}$, from the observed data $Y$, our estimates of these coefficients have error (i.e., uncertainty), such that the estimates are only as good as the data. Specifically, if we have fewer data points (i.e., $n$ is low), we have less certainty in $\hat{B}$. In lecture, we showed, that:</span>
<span id="cb81-170"><a href="#cb81-170" aria-hidden="true" tabindex="-1"></a>$$\hat{B} \sim N \left( B, (X^TX)^{-1} \hat{\sigma}^2 \right), $$</span>
<span id="cb81-171"><a href="#cb81-171" aria-hidden="true" tabindex="-1"></a>and we know that $\hat{\sigma}^2$ depends on sample size $n$, following:</span>
<span id="cb81-172"><a href="#cb81-172" aria-hidden="true" tabindex="-1"></a>$$\hat{\sigma}^2 \quad = \quad \frac{1}{n-p} (Y_{obs} - Y_{pred})^T (Y_{obs} - Y_{pred}) \quad = \quad \frac{1}{n-p} \hat{\epsilon}^T \hat{\epsilon}$$</span>
<span id="cb81-173"><a href="#cb81-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-174"><a href="#cb81-174" aria-hidden="true" tabindex="-1"></a>Using these equations, we showed then that $SE(\beta_i) = \sqrt{diag\left( (X^TX)^{-1} \right)_i \hat{\sigma}^2}$. Let's calculate this manually and compare to the output of the <span class="in">`lm()`</span> function.</span>
<span id="cb81-175"><a href="#cb81-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-178"><a href="#cb81-178" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-179"><a href="#cb81-179" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the model summary, which has useful components</span></span>
<span id="cb81-180"><a href="#cb81-180" aria-hidden="true" tabindex="-1"></a>lm_out_summary <span class="ot">=</span> <span class="fu">summary</span>(lm_out)</span>
<span id="cb81-181"><a href="#cb81-181" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the estimated residual standard deviation, sigma</span></span>
<span id="cb81-182"><a href="#cb81-182" aria-hidden="true" tabindex="-1"></a>est_sigma <span class="ot">=</span> lm_out_summary<span class="sc">$</span>sigma</span>
<span id="cb81-183"><a href="#cb81-183" aria-hidden="true" tabindex="-1"></a>est_sigma</span>
<span id="cb81-184"><a href="#cb81-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-185"><a href="#cb81-185" aria-hidden="true" tabindex="-1"></a><span class="co"># We already calculated (X^T X)^{-1} as inv_xtx</span></span>
<span id="cb81-186"><a href="#cb81-186" aria-hidden="true" tabindex="-1"></a>beta_cov_mat <span class="ot">=</span> inv_xtx <span class="sc">*</span> est_sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb81-187"><a href="#cb81-187" aria-hidden="true" tabindex="-1"></a>beta_cov_mat</span>
<span id="cb81-188"><a href="#cb81-188" aria-hidden="true" tabindex="-1"></a>se_beta <span class="ot">=</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(beta_cov_mat))</span>
<span id="cb81-189"><a href="#cb81-189" aria-hidden="true" tabindex="-1"></a>se_beta</span>
<span id="cb81-190"><a href="#cb81-190" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-191"><a href="#cb81-191" aria-hidden="true" tabindex="-1"></a>Compare these values to the output of the <span class="in">`summary()`</span> of @sec-lm-output in the column labelled <span class="in">`Std. Error`</span>.  </span>
<span id="cb81-192"><a href="#cb81-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-193"><a href="#cb81-193" aria-hidden="true" tabindex="-1"></a><span class="fu">## Confidence Intervals for $\hat{B}$ {#sec-conf-beta}</span></span>
<span id="cb81-194"><a href="#cb81-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-195"><a href="#cb81-195" aria-hidden="true" tabindex="-1"></a>To calculate confidence intervals for $\hat{B}$, we first must understand the $t$ (a.k.a. Student's $t$) probability distribution. This distribution represents the case when we are estimating the mean of a normally distributed variable and either the sample size is small or the variable's standard deviation is unknown. Essentially, the $t$ distribution increases the uncertainty (i.e., variance) in cases of low sample size (i.e., small $n$). With low sample size (and/or high number of parameters), the degrees of freedom of the $t$-distribution, $\nu$ is low, whereas with high sample size, $\nu$ is large. As $\nu$ approaches infinity, the $t$-distribution approximates the standard normal distribution (i.e., $N(\mu, \sigma)|\mu=0,\sigma=1$). </span>
<span id="cb81-198"><a href="#cb81-198" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-199"><a href="#cb81-199" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb81-200"><a href="#cb81-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-201"><a href="#cb81-201" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate x sequence</span></span>
<span id="cb81-202"><a href="#cb81-202" aria-hidden="true" tabindex="-1"></a>n_seq <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb81-203"><a href="#cb81-203" aria-hidden="true" tabindex="-1"></a>x_seq <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="at">length.out =</span> n_seq)</span>
<span id="cb81-204"><a href="#cb81-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-205"><a href="#cb81-205" aria-hidden="true" tabindex="-1"></a>t_pdf_nu2 <span class="ot">=</span> <span class="fu">dt</span>(x_seq, <span class="at">df =</span> <span class="dv">2</span>)</span>
<span id="cb81-206"><a href="#cb81-206" aria-hidden="true" tabindex="-1"></a>t_pdf_nu100 <span class="ot">=</span> <span class="fu">dt</span>(x_seq, <span class="at">df =</span> <span class="dv">100</span>)</span>
<span id="cb81-207"><a href="#cb81-207" aria-hidden="true" tabindex="-1"></a>norm_pdf <span class="ot">=</span> <span class="fu">dnorm</span>(x_seq, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb81-208"><a href="#cb81-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-209"><a href="#cb81-209" aria-hidden="true" tabindex="-1"></a><span class="co"># compare to t-100</span></span>
<span id="cb81-210"><a href="#cb81-210" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NA</span>,<span class="cn">NA</span>, <span class="at">xlab =</span> <span class="st">"x"</span>, <span class="at">ylab =</span> <span class="st">"P(x)"</span>, </span>
<span id="cb81-211"><a href="#cb81-211" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">range</span>(x_seq), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>))</span>
<span id="cb81-212"><a href="#cb81-212" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(norm_pdf<span class="sc">~</span>x_seq, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb81-213"><a href="#cb81-213" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(t_pdf_nu2<span class="sc">~</span>x_seq, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb81-214"><a href="#cb81-214" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(t_pdf_nu100<span class="sc">~</span>x_seq, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="fl">2.5</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb81-215"><a href="#cb81-215" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="fl">2.5</span>, <span class="at">y =</span> <span class="fl">0.4</span>,</span>
<span id="cb81-216"><a href="#cb81-216" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"Standard Normal"</span>, <span class="fu">expression</span>(<span class="fu">italic</span>(t)[<span class="dv">2</span>]), <span class="fu">expression</span>(<span class="fu">italic</span>(t)[<span class="dv">100</span>])),</span>
<span id="cb81-217"><a href="#cb81-217" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">lwd=</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"blue"</span>, <span class="st">"blue"</span>), <span class="at">bty =</span> <span class="st">"n"</span>)</span>
<span id="cb81-218"><a href="#cb81-218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-219"><a href="#cb81-219" aria-hidden="true" tabindex="-1"></a>It is the case for $\hat{B} \sim N \left( B, (X^TX)^{-1} \hat{\sigma}^2 \right)$ that we do not know the mean ($B$), and we are estimating the variance, $\hat{\sigma}^2$. Specifically, we are estimating the true mean vector, $B$, as $\hat{B}$, and we are estimating the variance of the residuals as $\hat{\sigma}^2$. We can therefore re-write the uncertainty in $\hat{B}$ as a multivariate $t$ distribution: </span>
<span id="cb81-220"><a href="#cb81-220" aria-hidden="true" tabindex="-1"></a>$$(\hat{B} - B) \sim t_{\nu} \left( 0, \Sigma \right),$$</span>
<span id="cb81-221"><a href="#cb81-221" aria-hidden="true" tabindex="-1"></a>where the means are zero, $\nu$ is the degrees of freedom (i.e., $n-p$), and $\Sigma = (X^TX)^{-1} \hat{\sigma}^2$. $(\hat{B} - B)$ represents the deviation of the estimated coefficients from the true coefficients, which is why the distribution is centered around zero. It is perhaps easier to separate the individual estimated coefficients, $\beta_i$, into their separate $t$-distributions:</span>
<span id="cb81-222"><a href="#cb81-222" aria-hidden="true" tabindex="-1"></a>$$\frac{(\hat{\beta}_i - \beta_i)}{SE(\hat{\beta}_i)} \sim t_{\nu}$$</span>
<span id="cb81-223"><a href="#cb81-223" aria-hidden="true" tabindex="-1"></a>$$(\hat{\beta}_i - \beta_i) \sim t_{\nu} SE(\hat{\beta}_i),$$</span>
<span id="cb81-224"><a href="#cb81-224" aria-hidden="true" tabindex="-1"></a>which shows that the $t$-distribution that describes the deviation of regression coefficients from the true value of those coefficients is scaled by the uncertainty in the estimated coefficients $SE(\hat{\beta}_i)$. As shown in Dr. Barber's materials, using this information, we can derive the confidence interval (at the $\alpha$ confidence level) calculation for $\hat{\beta}_i$ as: </span>
<span id="cb81-225"><a href="#cb81-225" aria-hidden="true" tabindex="-1"></a>$$ \hat{\beta}_i \pm t \left(\frac{1-\alpha}{2}, \nu \right) SE(\hat{\beta}_i),$$</span>
<span id="cb81-226"><a href="#cb81-226" aria-hidden="true" tabindex="-1"></a>where the $t()$ notation represents the *critical value* of the $t$-distribution, $t_{crit}$, with $\nu$ degrees of freedom, for which $P(z \le t_{crit}) = \frac{1-\alpha}{2}$, and $z$ is a continuous, random variable. This critical value can be calculated in R using the <span class="in">`qt()`</span> function, which we show below. </span>
<span id="cb81-227"><a href="#cb81-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-228"><a href="#cb81-228" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb81-229"><a href="#cb81-229" aria-hidden="true" tabindex="-1"></a><span class="fu">## Covariance of $\hat{\beta}_i$</span></span>
<span id="cb81-230"><a href="#cb81-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-231"><a href="#cb81-231" aria-hidden="true" tabindex="-1"></a>Although it is convenient and easier to digest the confidence interval of individual $\hat{\beta}_i$, we must realize that the estimates of the $\beta_i$ can covary (i.e., have non-zero covariance), which is quantified in the variance-covariance matrix of $\hat{B}$, $(X^TX)^{-1} \hat{\sigma}^2$. We will show why this is important below.</span>
<span id="cb81-232"><a href="#cb81-232" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb81-233"><a href="#cb81-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-234"><a href="#cb81-234" aria-hidden="true" tabindex="-1"></a>Let's manually calculate the 95% confidence intervals in $\hat{B}$ and compare to R's internal function <span class="in">`confint()`</span>.</span>
<span id="cb81-237"><a href="#cb81-237" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-238"><a href="#cb81-238" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the degrees of freedom from the model (\nu)</span></span>
<span id="cb81-239"><a href="#cb81-239" aria-hidden="true" tabindex="-1"></a><span class="co"># which can also be calculated as n - p</span></span>
<span id="cb81-240"><a href="#cb81-240" aria-hidden="true" tabindex="-1"></a>t_df <span class="ot">=</span> lm_out<span class="sc">$</span>df.residual</span>
<span id="cb81-241"><a href="#cb81-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-242"><a href="#cb81-242" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate t critical for alpha = 0.05</span></span>
<span id="cb81-243"><a href="#cb81-243" aria-hidden="true" tabindex="-1"></a><span class="co"># This will give us the 95% conf interval (CI)</span></span>
<span id="cb81-244"><a href="#cb81-244" aria-hidden="true" tabindex="-1"></a>t_crit <span class="ot">=</span> <span class="fu">qt</span>(<span class="dv">1</span><span class="sc">-</span>(<span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>), <span class="at">df =</span> t_df)</span>
<span id="cb81-245"><a href="#cb81-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-246"><a href="#cb81-246" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the upper and lower CI for both betas</span></span>
<span id="cb81-247"><a href="#cb81-247" aria-hidden="true" tabindex="-1"></a>ci_int <span class="ot">=</span> lm_coef[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>t_crit<span class="sc">*</span>se_beta[<span class="dv">1</span>]</span>
<span id="cb81-248"><a href="#cb81-248" aria-hidden="true" tabindex="-1"></a>ci_slope <span class="ot">=</span> lm_coef[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>t_crit<span class="sc">*</span>se_beta[<span class="dv">2</span>]</span>
<span id="cb81-249"><a href="#cb81-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-250"><a href="#cb81-250" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct a table of values</span></span>
<span id="cb81-251"><a href="#cb81-251" aria-hidden="true" tabindex="-1"></a>ci_mat <span class="ot">=</span> </span>
<span id="cb81-252"><a href="#cb81-252" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbind</span>(<span class="fu">c</span>(lm_coef[<span class="dv">1</span>], ci_int),</span>
<span id="cb81-253"><a href="#cb81-253" aria-hidden="true" tabindex="-1"></a>          <span class="fu">c</span>(lm_coef[<span class="dv">2</span>], ci_slope))</span>
<span id="cb81-254"><a href="#cb81-254" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(ci_mat) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"coef"</span>, <span class="st">"lowCI"</span>, <span class="st">"highCI"</span>)</span>
<span id="cb81-255"><a href="#cb81-255" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(ci_mat) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"intercept"</span>, <span class="st">"slope"</span>)</span>
<span id="cb81-256"><a href="#cb81-256" aria-hidden="true" tabindex="-1"></a>ci_mat</span>
<span id="cb81-257"><a href="#cb81-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-258"><a href="#cb81-258" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare these manual calculations to built-in</span></span>
<span id="cb81-259"><a href="#cb81-259" aria-hidden="true" tabindex="-1"></a><span class="co"># function confint(), which by default extracts the </span></span>
<span id="cb81-260"><a href="#cb81-260" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% CI for a lm() model's coefficients</span></span>
<span id="cb81-261"><a href="#cb81-261" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(lm_out)</span>
<span id="cb81-262"><a href="#cb81-262" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-263"><a href="#cb81-263" aria-hidden="true" tabindex="-1"></a><span class="fu">## Propagate uncertainty in $\hat{B}$ for predictions of $Y$</span></span>
<span id="cb81-264"><a href="#cb81-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-265"><a href="#cb81-265" aria-hidden="true" tabindex="-1"></a>There are several ways to calculate and visualize our uncertainty in model predictions of observed data $Y$ and unobserved data of the dependent variable (i.e., interpolation). The colored lines drawn on the figure in @sec-est-plot represent the expected values of $Y$ based on the OLS analysis' estimate of $\hat{B}$, but this line does not include uncertainty in these coefficient values. </span>
<span id="cb81-266"><a href="#cb81-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-267"><a href="#cb81-267" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multivariate $t$-distribution method</span></span>
<span id="cb81-268"><a href="#cb81-268" aria-hidden="true" tabindex="-1"></a>First, we will calculate uncertainty by sampling from the multivariate $t$ distribution that represents error in regression coefficients, $\hat{B}$. </span>
<span id="cb81-269"><a href="#cb81-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-272"><a href="#cb81-272" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-273"><a href="#cb81-273" aria-hidden="true" tabindex="-1"></a><span class="co"># We will "bootstrap" 1000 samples of intercept and slope</span></span>
<span id="cb81-274"><a href="#cb81-274" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb81-275"><a href="#cb81-275" aria-hidden="true" tabindex="-1"></a>n_samp <span class="ot">=</span> <span class="dv">500</span></span>
<span id="cb81-276"><a href="#cb81-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-277"><a href="#cb81-277" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw from the multivariate t </span></span>
<span id="cb81-278"><a href="#cb81-278" aria-hidden="true" tabindex="-1"></a><span class="co"># which represents (\hat{B} - B)</span></span>
<span id="cb81-279"><a href="#cb81-279" aria-hidden="true" tabindex="-1"></a>test_mat_deviates <span class="ot">=</span> </span>
<span id="cb81-280"><a href="#cb81-280" aria-hidden="true" tabindex="-1"></a>  mnormt<span class="sc">::</span><span class="fu">rmt</span>(n_samp, <span class="at">mean =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">S =</span> beta_cov_mat, <span class="at">df =</span> t_df)</span>
<span id="cb81-281"><a href="#cb81-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-282"><a href="#cb81-282" aria-hidden="true" tabindex="-1"></a><span class="co"># Now calculate the realized intercept and slope</span></span>
<span id="cb81-283"><a href="#cb81-283" aria-hidden="true" tabindex="-1"></a><span class="co"># using the t-distributed deviates</span></span>
<span id="cb81-284"><a href="#cb81-284" aria-hidden="true" tabindex="-1"></a>test_mat_t <span class="ot">=</span> <span class="fu">cbind</span>(</span>
<span id="cb81-285"><a href="#cb81-285" aria-hidden="true" tabindex="-1"></a>  lm_coef[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">c</span>(test_mat_deviates[,<span class="dv">1</span>]),</span>
<span id="cb81-286"><a href="#cb81-286" aria-hidden="true" tabindex="-1"></a>  lm_coef[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">c</span>(test_mat_deviates[,<span class="dv">2</span>])</span>
<span id="cb81-287"><a href="#cb81-287" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb81-288"><a href="#cb81-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-289"><a href="#cb81-289" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the 95% quantiles and compare to the </span></span>
<span id="cb81-290"><a href="#cb81-290" aria-hidden="true" tabindex="-1"></a><span class="co"># calculated 95% confidence intervals from above</span></span>
<span id="cb81-291"><a href="#cb81-291" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(test_mat_t, </span>
<span id="cb81-292"><a href="#cb81-292" aria-hidden="true" tabindex="-1"></a>      <span class="at">MARGIN =</span> <span class="dv">2</span>, <span class="co"># applies function (FUN) to columns (dim 2)</span></span>
<span id="cb81-293"><a href="#cb81-293" aria-hidden="true" tabindex="-1"></a>      <span class="at">FUN =</span> quantile, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span>))</span>
<span id="cb81-294"><a href="#cb81-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-295"><a href="#cb81-295" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare</span></span>
<span id="cb81-296"><a href="#cb81-296" aria-hidden="true" tabindex="-1"></a>ci_mat</span>
<span id="cb81-297"><a href="#cb81-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-298"><a href="#cb81-298" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the relationship between intercept and slope</span></span>
<span id="cb81-299"><a href="#cb81-299" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice the covariance</span></span>
<span id="cb81-300"><a href="#cb81-300" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(test_mat_t, <span class="at">xlab =</span> <span class="st">"Intercept"</span>, <span class="at">ylab =</span> <span class="st">"Slope"</span>)</span>
<span id="cb81-301"><a href="#cb81-301" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-302"><a href="#cb81-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-303"><a href="#cb81-303" aria-hidden="true" tabindex="-1"></a>Next, for each pair of intercept and slope randomly drawn above, we will calculate the expected values of $Y$ across the range of covariate $x$. We will then summarize the 95% quantile of expected $Y$ at each value of $x$ in this interpolation. To do this, we need a function to calculate the expected value of $Y$. This function will have the intercept and slope as inputs and will output the expected values of $Y$ across a range of $x$. Then, we will <span class="in">`apply()`</span> this function using all of the values of intercept and slope, in a vectorized and therefore very efficient manner, rather than using any <span class="in">`for`</span> loops. </span>
<span id="cb81-304"><a href="#cb81-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-307"><a href="#cb81-307" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-308"><a href="#cb81-308" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a matrix that holds the values of x</span></span>
<span id="cb81-309"><a href="#cb81-309" aria-hidden="true" tabindex="-1"></a><span class="co"># over which we want to interpolate the expected</span></span>
<span id="cb81-310"><a href="#cb81-310" aria-hidden="true" tabindex="-1"></a><span class="co"># values of Y</span></span>
<span id="cb81-311"><a href="#cb81-311" aria-hidden="true" tabindex="-1"></a>x_fake_mat <span class="ot">=</span> </span>
<span id="cb81-312"><a href="#cb81-312" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cbind</span>(</span>
<span id="cb81-313"><a href="#cb81-313" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rep</span>(<span class="dv">1</span>, <span class="at">times =</span> <span class="dv">100</span>),</span>
<span id="cb81-314"><a href="#cb81-314" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq</span>(<span class="dv">0</span>,<span class="fu">max</span>(x1),<span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb81-315"><a href="#cb81-315" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb81-316"><a href="#cb81-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-317"><a href="#cb81-317" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a function that will calculate the expected values</span></span>
<span id="cb81-318"><a href="#cb81-318" aria-hidden="true" tabindex="-1"></a>y_hat_fun <span class="ot">=</span> <span class="cf">function</span>(x, x_mat){</span>
<span id="cb81-319"><a href="#cb81-319" aria-hidden="true" tabindex="-1"></a>  x_mat <span class="sc">%*%</span> x</span>
<span id="cb81-320"><a href="#cb81-320" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb81-321"><a href="#cb81-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-322"><a href="#cb81-322" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply this function to all intercepts and slopes that</span></span>
<span id="cb81-323"><a href="#cb81-323" aria-hidden="true" tabindex="-1"></a><span class="co"># we drew from the multivariate t</span></span>
<span id="cb81-324"><a href="#cb81-324" aria-hidden="true" tabindex="-1"></a>y_pred_mt <span class="ot">=</span> <span class="fu">apply</span>(test_mat_t, <span class="dv">1</span>, y_hat_fun, <span class="at">x_mat=</span>x_fake_mat)</span>
<span id="cb81-325"><a href="#cb81-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-326"><a href="#cb81-326" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize the 95% quantile of the expected value of Y</span></span>
<span id="cb81-327"><a href="#cb81-327" aria-hidden="true" tabindex="-1"></a><span class="co"># at each value of x </span></span>
<span id="cb81-328"><a href="#cb81-328" aria-hidden="true" tabindex="-1"></a>y_pred_mt_summary <span class="ot">=</span> <span class="fu">apply</span>(y_pred_mt, <span class="dv">1</span>, quantile, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb81-329"><a href="#cb81-329" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(y_pred_mt_summary)</span>
<span id="cb81-330"><a href="#cb81-330" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-331"><a href="#cb81-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-332"><a href="#cb81-332" aria-hidden="true" tabindex="-1"></a><span class="fu">### `predict()` function method</span></span>
<span id="cb81-333"><a href="#cb81-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-334"><a href="#cb81-334" aria-hidden="true" tabindex="-1"></a>R has a built-in function <span class="in">`predict()`</span> (see specific variant <span class="in">`predict.lm()`</span>) which calculates expected values of the dependent variable from a linear regression model estimated using the function <span class="in">`lm()`</span>.</span>
<span id="cb81-335"><a href="#cb81-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-338"><a href="#cb81-338" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-339"><a href="#cb81-339" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that 'newdata' must be a data frame that includes the ranges</span></span>
<span id="cb81-340"><a href="#cb81-340" aria-hidden="true" tabindex="-1"></a><span class="co"># of each covariate in the regression model for which you want </span></span>
<span id="cb81-341"><a href="#cb81-341" aria-hidden="true" tabindex="-1"></a><span class="co"># to generate interpolated or predicted values of the dependent variable</span></span>
<span id="cb81-342"><a href="#cb81-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-343"><a href="#cb81-343" aria-hidden="true" tabindex="-1"></a><span class="co"># Here we are calculated the expected values as well as the </span></span>
<span id="cb81-344"><a href="#cb81-344" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% confidence intervals for those expected values</span></span>
<span id="cb81-345"><a href="#cb81-345" aria-hidden="true" tabindex="-1"></a>y_predict <span class="ot">=</span> <span class="fu">predict</span>(lm_out,</span>
<span id="cb81-346"><a href="#cb81-346" aria-hidden="true" tabindex="-1"></a>                 <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">x1 =</span> <span class="fu">c</span>(x_fake_mat[,<span class="dv">2</span>])),</span>
<span id="cb81-347"><a href="#cb81-347" aria-hidden="true" tabindex="-1"></a>                 <span class="at">interval =</span> <span class="st">"confidence"</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb81-348"><a href="#cb81-348" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(y_predict)</span>
<span id="cb81-349"><a href="#cb81-349" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-350"><a href="#cb81-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-351"><a href="#cb81-351" aria-hidden="true" tabindex="-1"></a><span class="fu">### Compare the two methods </span></span>
<span id="cb81-352"><a href="#cb81-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-353"><a href="#cb81-353" aria-hidden="true" tabindex="-1"></a>Let's visualize the output of the two methods to compare. </span>
<span id="cb81-354"><a href="#cb81-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-357"><a href="#cb81-357" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-358"><a href="#cb81-358" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb81-359"><a href="#cb81-359" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="cn">NA</span>,<span class="at">y=</span><span class="cn">NA</span>,<span class="at">xlab =</span> <span class="st">"x"</span>, <span class="at">ylab =</span> <span class="st">"y"</span>,</span>
<span id="cb81-360"><a href="#cb81-360" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">max</span>(x1)), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">25</span>), <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb81-361"><a href="#cb81-361" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the expected values of Y for each pair of int/slope </span></span>
<span id="cb81-362"><a href="#cb81-362" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_samp){</span>
<span id="cb81-363"><a href="#cb81-363" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(y_pred_mt[,i] <span class="sc">~</span> x_fake_mat[,<span class="dv">2</span>],</span>
<span id="cb81-364"><a href="#cb81-364" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reduce the opacity of each line</span></span>
<span id="cb81-365"><a href="#cb81-365" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> scales<span class="sc">::</span><span class="fu">alpha</span>(<span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.1</span>), <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb81-366"><a href="#cb81-366" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb81-367"><a href="#cb81-367" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the data points</span></span>
<span id="cb81-368"><a href="#cb81-368" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(y <span class="sc">~</span> x1, <span class="at">col =</span> <span class="st">'orange'</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb81-369"><a href="#cb81-369" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the expected values of Y from \hat{B}</span></span>
<span id="cb81-370"><a href="#cb81-370" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">coef =</span> lm_coef, <span class="at">col =</span> <span class="st">"orange"</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb81-371"><a href="#cb81-371" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the conf int of expected Y using multivariate t</span></span>
<span id="cb81-372"><a href="#cb81-372" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(y_pred_mt_summary[<span class="dv">1</span>,] <span class="sc">~</span> x_fake_mat[,<span class="dv">2</span>], <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">"orange"</span>)</span>
<span id="cb81-373"><a href="#cb81-373" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(y_pred_mt_summary[<span class="dv">2</span>,] <span class="sc">~</span> x_fake_mat[,<span class="dv">2</span>], <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">"orange"</span>)</span>
<span id="cb81-374"><a href="#cb81-374" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the conf int of expected Y using predict() function</span></span>
<span id="cb81-375"><a href="#cb81-375" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(y_predict[,<span class="st">"lwr"</span>]<span class="sc">~</span> x_fake_mat[,<span class="dv">2</span>], <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">"purple"</span>)</span>
<span id="cb81-376"><a href="#cb81-376" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(y_predict[,<span class="st">"upr"</span>]<span class="sc">~</span> x_fake_mat[,<span class="dv">2</span>], <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">"purple"</span>)</span>
<span id="cb81-377"><a href="#cb81-377" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-378"><a href="#cb81-378" aria-hidden="true" tabindex="-1"></a>There is yet a third option to calculate the uncertainty in predicted (i.e., interpolated or extrapolated) values of </span>
<span id="cb81-379"><a href="#cb81-379" aria-hidden="true" tabindex="-1"></a>$Y$, which is to derive an exact calculation of the confidence interval using the $t$ distribution, similar to that shown in @sec-conf-beta. See Ch4.1 of Dr. Barber's book for this derivation. </span>
<span id="cb81-380"><a href="#cb81-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-381"><a href="#cb81-381" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multiple Linear Regression</span></span>
<span id="cb81-382"><a href="#cb81-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-383"><a href="#cb81-383" aria-hidden="true" tabindex="-1"></a>So far, we have only discussed a single input variable in our model, which is a simple linear regression. When we have multiple input variables, we are dealing with multiple linear regression analysis, so the model looks like:</span>
<span id="cb81-384"><a href="#cb81-384" aria-hidden="true" tabindex="-1"></a>$$y_i = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \dots + \beta_{p-1} x_{p-1,i} + \epsilon_i$$</span>
<span id="cb81-385"><a href="#cb81-385" aria-hidden="true" tabindex="-1"></a>where $p$ is the number of model coefficients and $p-1$ is the number of input variables. Still, in matrix notation the model is $Y = XB + \epsilon$, so the least squares regression analysis approach still works. However, our interpretation of the model coefficients becomes a bit more challenging. </span>
<span id="cb81-386"><a href="#cb81-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-387"><a href="#cb81-387" aria-hidden="true" tabindex="-1"></a>Let's look at a data set within the <span class="in">`faraway`</span> package.</span>
<span id="cb81-390"><a href="#cb81-390" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-391"><a href="#cb81-391" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb81-392"><a href="#cb81-392" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb81-393"><a href="#cb81-393" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb81-394"><a href="#cb81-394" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 3.5</span></span>
<span id="cb81-395"><a href="#cb81-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-396"><a href="#cb81-396" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(faraway)</span>
<span id="cb81-397"><a href="#cb81-397" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(gala)</span>
<span id="cb81-398"><a href="#cb81-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-399"><a href="#cb81-399" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the raw data relationships</span></span>
<span id="cb81-400"><a href="#cb81-400" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb81-401"><a href="#cb81-401" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gala<span class="sc">$</span>Species <span class="sc">~</span> gala<span class="sc">$</span>Elevation, <span class="at">xlab =</span> <span class="st">"Elevation"</span>, <span class="at">ylab =</span> <span class="st">"Species"</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb81-402"><a href="#cb81-402" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gala<span class="sc">$</span>Species <span class="sc">~</span> gala<span class="sc">$</span>Area, <span class="at">xlab =</span> <span class="st">"Area"</span>, <span class="at">ylab =</span> <span class="st">"Species"</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb81-403"><a href="#cb81-403" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gala<span class="sc">$</span>Species <span class="sc">~</span> gala<span class="sc">$</span>Adjacent, <span class="at">xlab =</span> <span class="st">"Adjacent"</span>, <span class="at">ylab =</span> <span class="st">"Species"</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb81-404"><a href="#cb81-404" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb81-405"><a href="#cb81-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-406"><a href="#cb81-406" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct multiple and single linear regressionm, focusing on Elevation</span></span>
<span id="cb81-407"><a href="#cb81-407" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">=</span> <span class="fu">lm</span>(Species <span class="sc">~</span> Elevation <span class="sc">+</span> Area <span class="sc">+</span> Adjacent, <span class="at">data =</span> gala)</span>
<span id="cb81-408"><a href="#cb81-408" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">=</span> <span class="fu">lm</span>(Species <span class="sc">~</span> Elevation, <span class="at">data =</span> gala)</span>
<span id="cb81-409"><a href="#cb81-409" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(m1); <span class="fu">coef</span>(m2)</span>
<span id="cb81-410"><a href="#cb81-410" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-411"><a href="#cb81-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-414"><a href="#cb81-414" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-415"><a href="#cb81-415" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gala<span class="sc">$</span>Species <span class="sc">~</span> gala<span class="sc">$</span>Elevation, <span class="at">xlab =</span> <span class="st">"Elevation"</span>, <span class="at">ylab =</span> <span class="st">"Species"</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb81-416"><a href="#cb81-416" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">coef=</span><span class="fu">coef</span>(m1)[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>])</span>
<span id="cb81-417"><a href="#cb81-417" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">coef=</span><span class="fu">coef</span>(m2)[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb81-418"><a href="#cb81-418" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-419"><a href="#cb81-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-420"><a href="#cb81-420" aria-hidden="true" tabindex="-1"></a>What we see above is how the addition of <span class="in">`Area`</span> and <span class="in">`Adjacent`</span> input variables into the model "adjusts" the effect of <span class="in">`Elevation`</span>, leading to two unique estimates of the slope (i.e., effect) of <span class="in">`Elevation`</span>. Let's probe multiple linear regression more closely by using simulated data.</span>
<span id="cb81-421"><a href="#cb81-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-422"><a href="#cb81-422" aria-hidden="true" tabindex="-1"></a>First, let's simulate a model with 80 data points that correspond to observations of 4 input variables and one outcome variable. Note that in <span class="co">[</span><span class="ot">Footnotes @sec-mlr</span><span class="co">]</span>, we show a case with a categorical/binary input variable. </span>
<span id="cb81-425"><a href="#cb81-425" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-426"><a href="#cb81-426" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">80</span></span>
<span id="cb81-427"><a href="#cb81-427" aria-hidden="true" tabindex="-1"></a>n_covariate <span class="ot">=</span> <span class="dv">4</span></span>
<span id="cb81-428"><a href="#cb81-428" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> n_covariate <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb81-429"><a href="#cb81-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-430"><a href="#cb81-430" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">=</span> <span class="fu">vector</span>(<span class="st">"numeric"</span>, <span class="at">length =</span> p)</span>
<span id="cb81-431"><a href="#cb81-431" aria-hidden="true" tabindex="-1"></a>xmat <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n, <span class="at">ncol =</span> p)</span>
<span id="cb81-432"><a href="#cb81-432" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">=</span> <span class="fl">2.25</span></span>
<span id="cb81-433"><a href="#cb81-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-434"><a href="#cb81-434" aria-hidden="true" tabindex="-1"></a><span class="co"># Column for intercept</span></span>
<span id="cb81-435"><a href="#cb81-435" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">1</span>] <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb81-436"><a href="#cb81-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-437"><a href="#cb81-437" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the covariate data randomly:</span></span>
<span id="cb81-438"><a href="#cb81-438" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5</span>)</span>
<span id="cb81-439"><a href="#cb81-439" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">2</span>] <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">8</span>)</span>
<span id="cb81-440"><a href="#cb81-440" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">3</span>] <span class="ot">=</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">20</span>)</span>
<span id="cb81-441"><a href="#cb81-441" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">4</span>] <span class="ot">=</span> <span class="fu">rchisq</span>(n, <span class="at">df =</span> <span class="dv">50</span>)</span>
<span id="cb81-442"><a href="#cb81-442" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">5</span>] <span class="ot">=</span> <span class="fu">rpois</span>(n, <span class="at">lambda =</span> <span class="dv">10</span>)</span>
<span id="cb81-443"><a href="#cb81-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-444"><a href="#cb81-444" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb81-445"><a href="#cb81-445" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>p){</span>
<span id="cb81-446"><a href="#cb81-446" aria-hidden="true" tabindex="-1"></a>    <span class="fu">hist</span>(xmat[,i], <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"covariate "</span>, i<span class="dv">-1</span>))</span>
<span id="cb81-447"><a href="#cb81-447" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb81-448"><a href="#cb81-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-449"><a href="#cb81-449" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the betas:</span></span>
<span id="cb81-450"><a href="#cb81-450" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">1</span>] <span class="ot">=</span> <span class="fl">1.0</span></span>
<span id="cb81-451"><a href="#cb81-451" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">2</span>] <span class="ot">=</span> <span class="fl">0.75</span></span>
<span id="cb81-452"><a href="#cb81-452" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">3</span>] <span class="ot">=</span> <span class="sc">-</span><span class="fl">1.2</span></span>
<span id="cb81-453"><a href="#cb81-453" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">4</span>] <span class="ot">=</span> <span class="fl">0.0</span></span>
<span id="cb81-454"><a href="#cb81-454" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">5</span>] <span class="ot">=</span> <span class="fl">1.8</span></span>
<span id="cb81-455"><a href="#cb81-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-456"><a href="#cb81-456" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the observed 'y', adding residual error</span></span>
<span id="cb81-457"><a href="#cb81-457" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> xmat <span class="sc">%*%</span> betas <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb81-458"><a href="#cb81-458" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb81-459"><a href="#cb81-459" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y)</span>
<span id="cb81-460"><a href="#cb81-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-461"><a href="#cb81-461" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb81-462"><a href="#cb81-462" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>p){</span>
<span id="cb81-463"><a href="#cb81-463" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(y <span class="sc">~</span> xmat[,i],</span>
<span id="cb81-464"><a href="#cb81-464" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="fu">paste</span>(<span class="st">"covariate "</span>, i<span class="dv">-1</span>))</span>
<span id="cb81-465"><a href="#cb81-465" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb81-466"><a href="#cb81-466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-467"><a href="#cb81-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-468"><a href="#cb81-468" aria-hidden="true" tabindex="-1"></a>How do we figure out the expected value of $y$ for a particular situation? Here's an example. What is the expected value of $y$ when $x_2 = 0.5$, but the rest of the input variables are at their average values?</span>
<span id="cb81-469"><a href="#cb81-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-472"><a href="#cb81-472" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-473"><a href="#cb81-473" aria-hidden="true" tabindex="-1"></a><span class="co"># Written out long-ways:</span></span>
<span id="cb81-474"><a href="#cb81-474" aria-hidden="true" tabindex="-1"></a>pred_y <span class="ot">=</span> </span>
<span id="cb81-475"><a href="#cb81-475" aria-hidden="true" tabindex="-1"></a>    betas[<span class="dv">1</span>]<span class="sc">*</span><span class="dv">1</span> <span class="sc">+</span> </span>
<span id="cb81-476"><a href="#cb81-476" aria-hidden="true" tabindex="-1"></a>    betas[<span class="dv">2</span>]<span class="sc">*</span><span class="fu">mean</span>(xmat[,<span class="dv">2</span>]) <span class="sc">+</span> </span>
<span id="cb81-477"><a href="#cb81-477" aria-hidden="true" tabindex="-1"></a>    betas[<span class="dv">3</span>]<span class="sc">*</span><span class="fl">0.5</span> <span class="sc">+</span> </span>
<span id="cb81-478"><a href="#cb81-478" aria-hidden="true" tabindex="-1"></a>    betas[<span class="dv">4</span>]<span class="sc">*</span><span class="fu">mean</span>(xmat[,<span class="dv">4</span>]) <span class="sc">+</span> </span>
<span id="cb81-479"><a href="#cb81-479" aria-hidden="true" tabindex="-1"></a>    betas[<span class="dv">5</span>]<span class="sc">*</span><span class="fu">mean</span>(xmat[,<span class="dv">5</span>]) </span>
<span id="cb81-480"><a href="#cb81-480" aria-hidden="true" tabindex="-1"></a>pred_y</span>
<span id="cb81-481"><a href="#cb81-481" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-482"><a href="#cb81-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-483"><a href="#cb81-483" aria-hidden="true" tabindex="-1"></a>Now let's use ordinary least squares regression to estimate our model coefficients from the data, and then compare these to our "known" values of the model parameters. </span>
<span id="cb81-484"><a href="#cb81-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-487"><a href="#cb81-487" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-488"><a href="#cb81-488" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the model:</span></span>
<span id="cb81-489"><a href="#cb81-489" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> xmat)</span>
<span id="cb81-490"><a href="#cb81-490" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that the following two models give the same results</span></span>
<span id="cb81-491"><a href="#cb81-491" aria-hidden="true" tabindex="-1"></a><span class="co">#m2 = lm(y ~ 0 + X1 + X2 + X3 + X4 + X5, data = data.frame(xmat))</span></span>
<span id="cb81-492"><a href="#cb81-492" aria-hidden="true" tabindex="-1"></a><span class="co">#m3 = lm(y ~ 1 + X2 + X3 + X4 + X5, data = data.frame(xmat))</span></span>
<span id="cb81-493"><a href="#cb81-493" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1)</span>
<span id="cb81-494"><a href="#cb81-494" aria-hidden="true" tabindex="-1"></a><span class="co">#summary(m2)</span></span>
<span id="cb81-495"><a href="#cb81-495" aria-hidden="true" tabindex="-1"></a><span class="co">#summary(m3)</span></span>
<span id="cb81-496"><a href="#cb81-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-497"><a href="#cb81-497" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare known `betas` to estimated coefficients</span></span>
<span id="cb81-498"><a href="#cb81-498" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(betas, <span class="fu">coef</span>(m1)) </span>
<span id="cb81-499"><a href="#cb81-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-500"><a href="#cb81-500" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the regression lines with abline</span></span>
<span id="cb81-501"><a href="#cb81-501" aria-hidden="true" tabindex="-1"></a>coef_m1 <span class="ot">=</span> <span class="fu">coef</span>(m1)</span>
<span id="cb81-502"><a href="#cb81-502" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb81-503"><a href="#cb81-503" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>p){</span>
<span id="cb81-504"><a href="#cb81-504" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb81-505"><a href="#cb81-505" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(y <span class="sc">~</span> xmat[,i], <span class="at">pch=</span><span class="dv">19</span>,</span>
<span id="cb81-506"><a href="#cb81-506" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="fu">paste</span>(<span class="st">"covariate "</span>, i<span class="dv">-1</span>),</span>
<span id="cb81-507"><a href="#cb81-507" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">"y"</span>,</span>
<span id="cb81-508"><a href="#cb81-508" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylim =</span> <span class="fu">range</span>(y))</span>
<span id="cb81-509"><a href="#cb81-509" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">coef=</span>coef_m1[<span class="fu">c</span>(<span class="dv">1</span>,i)])</span>
<span id="cb81-510"><a href="#cb81-510" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb81-511"><a href="#cb81-511" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-512"><a href="#cb81-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-513"><a href="#cb81-513" aria-hidden="true" tabindex="-1"></a>Well, those regression lines do not look correct. That is because we are interpretting the slopes and intercepts a little incorrectly and not plotting them in the correct manner. </span>
<span id="cb81-514"><a href="#cb81-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-515"><a href="#cb81-515" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb81-516"><a href="#cb81-516" aria-hidden="true" tabindex="-1"></a><span class="fu">## How to plot the output of `lm()` for multiple linear regression</span></span>
<span id="cb81-517"><a href="#cb81-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-518"><a href="#cb81-518" aria-hidden="true" tabindex="-1"></a>When we isolate and visualize the relationship between the outcome and a single input variable, what we are really observing is the adjusted relationship, after accounting for the other input variables in the model. To understand the expected value of $y$ for any particular value of the single input variable, we really need to set the other input variables to their mean value. Let's demonstrate this below with the <span class="in">`predict()`</span> function.</span>
<span id="cb81-519"><a href="#cb81-519" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb81-520"><a href="#cb81-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-521"><a href="#cb81-521" aria-hidden="true" tabindex="-1"></a>Let's determine the expected values of $y$ for input variable 2 ($x_2$) and plot it.</span>
<span id="cb81-522"><a href="#cb81-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-525"><a href="#cb81-525" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-526"><a href="#cb81-526" aria-hidden="true" tabindex="-1"></a><span class="co"># Prediction for covariate 2 when all other input vars at mean</span></span>
<span id="cb81-527"><a href="#cb81-527" aria-hidden="true" tabindex="-1"></a>my_df <span class="ot">=</span> <span class="fu">data.frame</span>(xmat[,<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>])</span>
<span id="cb81-528"><a href="#cb81-528" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(my_df)</span>
<span id="cb81-529"><a href="#cb81-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-530"><a href="#cb81-530" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run the model but with just the input variables, </span></span>
<span id="cb81-531"><a href="#cb81-531" aria-hidden="true" tabindex="-1"></a><span class="co"># and the intercept is implicit</span></span>
<span id="cb81-532"><a href="#cb81-532" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3 <span class="sc">+</span> X4, <span class="at">data =</span> my_df)</span>
<span id="cb81-533"><a href="#cb81-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-534"><a href="#cb81-534" aria-hidden="true" tabindex="-1"></a><span class="co"># Now let's try to predict y across a range of </span></span>
<span id="cb81-535"><a href="#cb81-535" aria-hidden="true" tabindex="-1"></a><span class="co"># input variable 2,</span></span>
<span id="cb81-536"><a href="#cb81-536" aria-hidden="true" tabindex="-1"></a><span class="co"># while holding the other input variables at</span></span>
<span id="cb81-537"><a href="#cb81-537" aria-hidden="true" tabindex="-1"></a><span class="co"># their average values</span></span>
<span id="cb81-538"><a href="#cb81-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-539"><a href="#cb81-539" aria-hidden="true" tabindex="-1"></a>n_pred <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb81-540"><a href="#cb81-540" aria-hidden="true" tabindex="-1"></a>new_df <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb81-541"><a href="#cb81-541" aria-hidden="true" tabindex="-1"></a>  <span class="at">X1 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X1), n_pred),</span>
<span id="cb81-542"><a href="#cb81-542" aria-hidden="true" tabindex="-1"></a>  <span class="at">X2 =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="at">length.out =</span> n_pred),</span>
<span id="cb81-543"><a href="#cb81-543" aria-hidden="true" tabindex="-1"></a>  <span class="at">X3 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X3), n_pred),</span>
<span id="cb81-544"><a href="#cb81-544" aria-hidden="true" tabindex="-1"></a>  <span class="at">X4 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X4), n_pred)</span>
<span id="cb81-545"><a href="#cb81-545" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb81-546"><a href="#cb81-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-547"><a href="#cb81-547" aria-hidden="true" tabindex="-1"></a>y_pred2 <span class="ot">=</span> <span class="fu">predict</span>(m2, <span class="at">newdata =</span> new_df)</span>
<span id="cb81-548"><a href="#cb81-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-549"><a href="#cb81-549" aria-hidden="true" tabindex="-1"></a><span class="co"># Now plot:</span></span>
<span id="cb81-550"><a href="#cb81-550" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb81-551"><a href="#cb81-551" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> my_df<span class="sc">$</span>X2, <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb81-552"><a href="#cb81-552" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"covariate 2"</span>, <span class="at">ylab =</span> <span class="st">"y"</span>)</span>
<span id="cb81-553"><a href="#cb81-553" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(y_pred2 <span class="sc">~</span> new_df<span class="sc">$</span>X2)</span>
<span id="cb81-554"><a href="#cb81-554" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-555"><a href="#cb81-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-556"><a href="#cb81-556" aria-hidden="true" tabindex="-1"></a>Now we see that the <span class="in">`predict()`</span> function shows a more intuitive relationship between input variable $x_2$ and outcome $y$, *while accounting for the effects of the three other input variables*.</span>
<span id="cb81-557"><a href="#cb81-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-558"><a href="#cb81-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-559"><a href="#cb81-559" aria-hidden="true" tabindex="-1"></a><span class="fu">## Footnotes</span></span>
<span id="cb81-560"><a href="#cb81-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-561"><a href="#cb81-561" aria-hidden="true" tabindex="-1"></a><span class="fu">### Euclidean norm &amp; cross product {#sec-crossprod}</span></span>
<span id="cb81-562"><a href="#cb81-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-563"><a href="#cb81-563" aria-hidden="true" tabindex="-1"></a>We often see the syntax, $|| a ||$, which is the Euclidean norm of the $n$-sized vector $a$: $$|| a || = \left( \sum_{i=1}^{n} a_i^2 \right) ^ {1/2} ,$$ so that when we see $|| a ||^2$, this results in the sum of squares of vector $a$, $\sum_{i=1}^{n} a_i^2$.</span>
<span id="cb81-564"><a href="#cb81-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-565"><a href="#cb81-565" aria-hidden="true" tabindex="-1"></a>In the context of least squares regression, we are trying to minimize the residual sum of squares, where the residuals, $\epsilon_i$, are in vector, $\epsilon$. The sum of squares of vector $\epsilon$ is therefore $|| \epsilon ||^2$. Algebraically, we can find this value as the cross product of $\epsilon$, which is $\epsilon^{T}\epsilon$. Let's do a coded example with vector $x$.</span>
<span id="cb81-566"><a href="#cb81-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-569"><a href="#cb81-569" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-570"><a href="#cb81-570" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector of real numbers</span></span>
<span id="cb81-571"><a href="#cb81-571" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb81-572"><a href="#cb81-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-573"><a href="#cb81-573" aria-hidden="true" tabindex="-1"></a><span class="co"># sum of squares</span></span>
<span id="cb81-574"><a href="#cb81-574" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(x<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb81-575"><a href="#cb81-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-576"><a href="#cb81-576" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluated as cross-product</span></span>
<span id="cb81-577"><a href="#cb81-577" aria-hidden="true" tabindex="-1"></a><span class="fu">t</span>(x) <span class="sc">%*%</span> x</span>
<span id="cb81-578"><a href="#cb81-578" aria-hidden="true" tabindex="-1"></a><span class="do">## Or with crossprod()</span></span>
<span id="cb81-579"><a href="#cb81-579" aria-hidden="true" tabindex="-1"></a><span class="fu">crossprod</span>(x,x)</span>
<span id="cb81-580"><a href="#cb81-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-581"><a href="#cb81-581" aria-hidden="true" tabindex="-1"></a><span class="co"># Euclidean norm also known as the 2-norm</span></span>
<span id="cb81-582"><a href="#cb81-582" aria-hidden="true" tabindex="-1"></a><span class="co"># so sum of squares is 2-norm, squared</span></span>
<span id="cb81-583"><a href="#cb81-583" aria-hidden="true" tabindex="-1"></a><span class="fu">norm</span>(x, <span class="at">type =</span> <span class="st">"2"</span>) <span class="sc">^</span> <span class="dv">2</span></span>
<span id="cb81-584"><a href="#cb81-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-585"><a href="#cb81-585" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-586"><a href="#cb81-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-587"><a href="#cb81-587" aria-hidden="true" tabindex="-1"></a><span class="fu">### `solve()` and Inverse of matrix {#sec-solve}</span></span>
<span id="cb81-588"><a href="#cb81-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-589"><a href="#cb81-589" aria-hidden="true" tabindex="-1"></a>Suppose we have matrices $A$, $X$, and $B$, and the following expression is true: $$AX=B.$$</span>
<span id="cb81-590"><a href="#cb81-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-591"><a href="#cb81-591" aria-hidden="true" tabindex="-1"></a>Then, suppose $X$ is unknown, such that we want to find the solution for $X$, when we rearrange: $$X = A^{-1} B,$$ where $A^{-1}$ is the multiplicative inverse of matrix $A$. To figure this out computationally, we can use the <span class="in">`solve()`</span> function in R, as long as $A$ is a square matrix and has an inverse.</span>
<span id="cb81-592"><a href="#cb81-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-595"><a href="#cb81-595" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-596"><a href="#cb81-596" aria-hidden="true" tabindex="-1"></a><span class="co"># Create A and known X</span></span>
<span id="cb81-597"><a href="#cb81-597" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,</span>
<span id="cb81-598"><a href="#cb81-598" aria-hidden="true" tabindex="-1"></a>             <span class="dv">5</span>,<span class="dv">2</span>), <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb81-599"><a href="#cb81-599" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), <span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb81-600"><a href="#cb81-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-601"><a href="#cb81-601" aria-hidden="true" tabindex="-1"></a><span class="co"># Dot product to calculate B</span></span>
<span id="cb81-602"><a href="#cb81-602" aria-hidden="true" tabindex="-1"></a>B <span class="ot">=</span> A <span class="sc">%*%</span> X</span>
<span id="cb81-603"><a href="#cb81-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-604"><a href="#cb81-604" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppose you have A and B, but want to find X</span></span>
<span id="cb81-605"><a href="#cb81-605" aria-hidden="true" tabindex="-1"></a>X_solve <span class="ot">=</span> <span class="fu">solve</span>(A, B)</span>
<span id="cb81-606"><a href="#cb81-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-607"><a href="#cb81-607" aria-hidden="true" tabindex="-1"></a><span class="co"># Did it work?</span></span>
<span id="cb81-608"><a href="#cb81-608" aria-hidden="true" tabindex="-1"></a>X; X_solve</span>
<span id="cb81-609"><a href="#cb81-609" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-610"><a href="#cb81-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-611"><a href="#cb81-611" aria-hidden="true" tabindex="-1"></a>We can see, then, that <span class="in">`solve()`</span> is internally evaluating $A^{-1}$. Remember that $A^{-1}$ is not trivial to calculate, as it is the matrix that must satisfy: $AA^{-1} = I$, where $I$ is an identity matrix. In fact, <span class="in">`solve(A)`</span> returns the inverse of $A$, if it exists.</span>
<span id="cb81-612"><a href="#cb81-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-615"><a href="#cb81-615" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-616"><a href="#cb81-616" aria-hidden="true" tabindex="-1"></a>inv_A <span class="ot">=</span> <span class="fu">solve</span>(A)</span>
<span id="cb81-617"><a href="#cb81-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-618"><a href="#cb81-618" aria-hidden="true" tabindex="-1"></a><span class="co">#Did it work?</span></span>
<span id="cb81-619"><a href="#cb81-619" aria-hidden="true" tabindex="-1"></a>(inv_A <span class="sc">%*%</span> B)</span>
<span id="cb81-620"><a href="#cb81-620" aria-hidden="true" tabindex="-1"></a>X</span>
<span id="cb81-621"><a href="#cb81-621" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-622"><a href="#cb81-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-623"><a href="#cb81-623" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multiple linear regression with a categorical input {#sec-mlr}</span></span>
<span id="cb81-624"><a href="#cb81-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-625"><a href="#cb81-625" aria-hidden="true" tabindex="-1"></a>Let's simulate a case in which we have one categorical input variable that takes on values "low", "medium", and "high", and one continuous input variable. </span>
<span id="cb81-628"><a href="#cb81-628" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-629"><a href="#cb81-629" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">7</span>)</span>
<span id="cb81-630"><a href="#cb81-630" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">90</span></span>
<span id="cb81-631"><a href="#cb81-631" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">=</span> <span class="fl">0.8</span></span>
<span id="cb81-632"><a href="#cb81-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-633"><a href="#cb81-633" aria-hidden="true" tabindex="-1"></a><span class="co"># Xmatrix</span></span>
<span id="cb81-634"><a href="#cb81-634" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept</span></span>
<span id="cb81-635"><a href="#cb81-635" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="at">times =</span> n) </span>
<span id="cb81-636"><a href="#cb81-636" aria-hidden="true" tabindex="-1"></a><span class="do">## Categorical input variable</span></span>
<span id="cb81-637"><a href="#cb81-637" aria-hidden="true" tabindex="-1"></a><span class="do">### Note that we need to code this as "0" "1" "2" to </span></span>
<span id="cb81-638"><a href="#cb81-638" aria-hidden="true" tabindex="-1"></a><span class="do">### simulate our outcome variable "y"</span></span>
<span id="cb81-639"><a href="#cb81-639" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">each=</span>n<span class="sc">/</span><span class="dv">3</span>)</span>
<span id="cb81-640"><a href="#cb81-640" aria-hidden="true" tabindex="-1"></a>x1L <span class="ot">=</span> <span class="fu">factor</span>(x1, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"low"</span>, <span class="st">"med"</span>, <span class="st">"high"</span>))</span>
<span id="cb81-641"><a href="#cb81-641" aria-hidden="true" tabindex="-1"></a><span class="do">## Continuous input variable</span></span>
<span id="cb81-642"><a href="#cb81-642" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="fl">2.5</span>)</span>
<span id="cb81-643"><a href="#cb81-643" aria-hidden="true" tabindex="-1"></a>xmat <span class="ot">=</span> <span class="fu">cbind</span>(x0,x1,x2)</span>
<span id="cb81-644"><a href="#cb81-644" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(xmat)</span>
<span id="cb81-645"><a href="#cb81-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-646"><a href="#cb81-646" aria-hidden="true" tabindex="-1"></a><span class="co"># Intercept and 2 slopes</span></span>
<span id="cb81-647"><a href="#cb81-647" aria-hidden="true" tabindex="-1"></a>betas<span class="ot">=</span><span class="fu">c</span>(<span class="fl">1.5</span>, <span class="fl">1.2</span>, <span class="sc">-</span><span class="fl">1.5</span>)</span>
<span id="cb81-648"><a href="#cb81-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-649"><a href="#cb81-649" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate outcome variable, as usual</span></span>
<span id="cb81-650"><a href="#cb81-650" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">=</span> xmat <span class="sc">%*%</span> betas <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,sigma)</span>
<span id="cb81-651"><a href="#cb81-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-652"><a href="#cb81-652" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the relationships</span></span>
<span id="cb81-653"><a href="#cb81-653" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb81-654"><a href="#cb81-654" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y2<span class="sc">~</span>x1)</span>
<span id="cb81-655"><a href="#cb81-655" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y2<span class="sc">~</span>x2)</span>
<span id="cb81-656"><a href="#cb81-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-657"><a href="#cb81-657" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the model</span></span>
<span id="cb81-658"><a href="#cb81-658" aria-hidden="true" tabindex="-1"></a><span class="do">## Note that we us the "factor" input variable</span></span>
<span id="cb81-659"><a href="#cb81-659" aria-hidden="true" tabindex="-1"></a><span class="do">## "x1L", which has "levels"</span></span>
<span id="cb81-660"><a href="#cb81-660" aria-hidden="true" tabindex="-1"></a>m_cat <span class="ot">=</span> <span class="fu">lm</span>(y2 <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x1L <span class="sc">+</span> x2)</span>
<span id="cb81-661"><a href="#cb81-661" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_cat)</span>
<span id="cb81-662"><a href="#cb81-662" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(m_cat)</span>
<span id="cb81-663"><a href="#cb81-663" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-664"><a href="#cb81-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-665"><a href="#cb81-665" aria-hidden="true" tabindex="-1"></a>How do we interpret the slopes, because we see there is a separate slope for <span class="in">`x1Lmed`</span> and <span class="in">`x1Lhigh`</span>? We can understand better by seeing how the linear model addes up. For instance, what is the expected value of the outcome variable when $x_1$ is <span class="in">`high`</span>, and $x_2 = 2.0$?</span>
<span id="cb81-666"><a href="#cb81-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-669"><a href="#cb81-669" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb81-670"><a href="#cb81-670" aria-hidden="true" tabindex="-1"></a><span class="do">## Using m1_binL:</span></span>
<span id="cb81-671"><a href="#cb81-671" aria-hidden="true" tabindex="-1"></a>y2_pred <span class="ot">=</span> </span>
<span id="cb81-672"><a href="#cb81-672" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">*</span><span class="fu">coef</span>(m_cat)[<span class="dv">1</span>] <span class="sc">+</span> <span class="co"># Global average (intercept)</span></span>
<span id="cb81-673"><a href="#cb81-673" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span><span class="sc">*</span><span class="fu">coef</span>(m_cat)[<span class="dv">2</span>] <span class="sc">+</span> <span class="co"># Not "med"</span></span>
<span id="cb81-674"><a href="#cb81-674" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">*</span><span class="fu">coef</span>(m_cat)[<span class="dv">3</span>] <span class="sc">+</span> <span class="co"># Yes "high"</span></span>
<span id="cb81-675"><a href="#cb81-675" aria-hidden="true" tabindex="-1"></a>    <span class="fl">2.0</span><span class="sc">*</span><span class="fu">coef</span>(m_cat)[<span class="dv">4</span>] <span class="co"># x2=2.0 * slope</span></span>
<span id="cb81-676"><a href="#cb81-676" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(y2_pred)</span>
<span id="cb81-677"><a href="#cb81-677" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb81-678"><a href="#cb81-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-679"><a href="#cb81-679" aria-hidden="true" tabindex="-1"></a>When we assigned the slope of the categorical input variable as $1.2$, remember this is the expected change in $y$ as the input variable changes by a value of $1.0$. In the model, we code the $x_1$ variable as taking numerical values $0$, $1$, and $2$ to represent categories, "low", "medium", and "high". So, the slope for <span class="in">`x1med`</span> is the expected change in $y$ as the input variable changes from "low" to "medium", an effective change of $1.0$. Then, the slope for <span class="in">`x1high`</span> is the expected change in $y$ as the input variable changes from "low" to "high", an effective change of $2.0$; hence, this slope is estimated as $2.29$, with standard error $0.19$. Notice how this slope is approximately twice our "known" slope for the input variable, which was $1.2$.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>